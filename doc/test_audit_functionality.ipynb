{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Toponymy Audit Functionality\n",
    "\n",
    "This notebook demonstrates how to use the new audit functionality in Toponymy to compare intermediate results (keyphrases, exemplars, subtopics) with final LLM-generated topic names.\n",
    "\n",
    "**Important**: Make sure to select the \"Python 3.10 (toponymy-test)\" kernel to run this notebook with all dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Import Toponymy and the new audit functions\n",
    "from toponymy import Toponymy, ToponymyClusterer\n",
    "from toponymy.audit import (\n",
    "    create_audit_df,\n",
    "    create_comparison_df,\n",
    "    create_keyphrase_analysis_df,\n",
    "    create_layer_summary_df,\n",
    "    create_prompt_analysis_df,\n",
    "    export_audit_excel,\n",
    "    get_cluster_details,\n",
    "    get_cluster_documents  # New function added\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data\n",
    "\n",
    "We'll use the 20-newsgroups dataset as shown in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20-newsgroups dataset...\n",
      "Loaded 18170 documents\n",
      "Document vectors shape: (18170, 768)\n",
      "Document map shape: (18170, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the 20-newsgroups dataset with precomputed embeddings\n",
    "print(\"Loading 20-newsgroups dataset...\")\n",
    "newsgroups_df = pd.read_parquet(\"hf://datasets/lmcinnes/20newsgroups_embedded/data/train-00000-of-00001.parquet\")\n",
    "\n",
    "# Extract text, vectors, and map\n",
    "text = newsgroups_df[\"post\"].str.strip().values\n",
    "document_vectors = np.stack(newsgroups_df[\"embedding\"].values)\n",
    "document_map = np.stack(newsgroups_df[\"map\"].values)\n",
    "\n",
    "print(f\"Loaded {len(text)} documents\")\n",
    "print(f\"Document vectors shape: {document_vectors.shape}\")\n",
    "print(f\"Document map shape: {document_map.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models\n",
    "\n",
    "Set up the embedding model and LLM wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "OpenAI model initialized!\n",
      "Using model: gpt-4o-mini\n",
      "Ready to generate topic names using OpenAI API\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize OpenAI LLM wrapper\n",
    "import os\n",
    "\n",
    "# IMPORTANT: Replace with your actual OpenAI API key\n",
    "# You can get one at: https://platform.openai.com/api-keys\n",
    "#openai_api_key = \"sk-YOUR-API-KEY-HERE\"  \n",
    "\n",
    "\n",
    "\n",
    "# Alternative: Load from environment variable (recommended for security)\n",
    "#openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Alternative: Load from a file\n",
    "# with open(\"openai_key.txt\", \"r\") as f:\n",
    "#     openai_api_key = f.read().strip()\n",
    "\n",
    "# Import OpenAI from the correct module\n",
    "import toponymy.llm_wrappers\n",
    "OpenAI = toponymy.llm_wrappers.OpenAINamer\n",
    "\n",
    "# Create OpenAI wrapper\n",
    "# Default model is gpt-4o-mini which is cost-effective for topic naming\n",
    "llm = OpenAINamer(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "\n",
    "print(\"OpenAI model initialized!\")\n",
    "print(f\"Using model: {llm.model}\")\n",
    "print(\"Ready to generate topic names using OpenAI API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Fit Toponymy Model\n",
    "\n",
    "We'll use a smaller subset for faster testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset of 3000 documents for testing\n"
     ]
    }
   ],
   "source": [
    "# Use a subset for faster testing\n",
    "subset_size = 3000\n",
    "text_subset = text[:subset_size]\n",
    "vectors_subset = document_vectors[:subset_size]\n",
    "map_subset = document_map[:subset_size]\n",
    "\n",
    "print(f\"Using subset of {subset_size} documents for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated OpenAI API costs for this test:\n",
      "  Input tokens: ~20,000 ($0.0030)\n",
      "  Output tokens: ~400 ($0.0002)\n",
      "  Total estimated cost: $0.0032\n",
      "\n",
      "Note: Actual costs may vary. Using subset_size=3000 documents\n"
     ]
    }
   ],
   "source": [
    "# Estimate API costs before running\n",
    "# GPT-4o-mini pricing (as of 2024): $0.15 per 1M input tokens, $0.60 per 1M output tokens\n",
    "\n",
    "# Rough estimation\n",
    "estimated_clusters = 20  # Approximate number of clusters across all layers\n",
    "estimated_tokens_per_prompt = 1000  # Each prompt with keyphrases and exemplars\n",
    "estimated_output_tokens = 20  # Topic names are short\n",
    "\n",
    "total_input_tokens = estimated_clusters * estimated_tokens_per_prompt\n",
    "total_output_tokens = estimated_clusters * estimated_output_tokens\n",
    "\n",
    "# Calculate costs (prices in USD)\n",
    "input_cost = (total_input_tokens / 1_000_000) * 0.15\n",
    "output_cost = (total_output_tokens / 1_000_000) * 0.60\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(f\"Estimated OpenAI API costs for this test:\")\n",
    "print(f\"  Input tokens: ~{total_input_tokens:,} (${input_cost:.4f})\")\n",
    "print(f\"  Output tokens: ~{total_output_tokens:,} (${output_cost:.4f})\")\n",
    "print(f\"  Total estimated cost: ${total_cost:.4f}\")\n",
    "print(f\"\\nNote: Actual costs may vary. Using subset_size={subset_size} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Toponymy model...\n",
      "This will make API calls to OpenAI - costs will apply!\n",
      "Layer 0 found 80 clusters\n",
      "Layer 1 found 26 clusters\n",
      "Layer 2 found 10 clusters\n",
      "Layer 3 found 4 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecting facility_location exemplars:   0%|                                                                                                                                                  | 0/80 [00:00<?, ?cluster/s]\u001b[A\n",
      "Selecting facility_location exemplars: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 799.91cluster/s]\u001b[A\n",
      "Batches:   0%|                                                                                                                                                                                   | 0/1255 [00:00<?, ?it/s]/Users/keyu/miniconda3/envs/toponymy-test/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1255/1255 [00:28<00:00, 44.05it/s]\n",
      "Building topic names by layer:   0%|                                                                                                                                                             | 0/4 [00:00<?, ?layer/s]\n",
      "Generating informative keyphrases:   0%|                                                                                                                                                      | 0/80 [00:00<?, ?cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  14%|███████████████████▍                                                                                                                         | 11/80 [00:00<00:00, 99.52cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  29%|████████████████████████████████████████▎                                                                                                   | 23/80 [00:00<00:00, 108.96cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  42%|███████████████████████████████████████████████████████████▌                                                                                | 34/80 [00:00<00:00, 101.29cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  56%|██████████████████████████████████████████████████████████████████████████████▊                                                             | 45/80 [00:00<00:00, 101.39cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  70%|██████████████████████████████████████████████████████████████████████████████████████████████████                                          | 56/80 [00:00<00:00, 103.93cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 67/80 [00:00<00:00, 104.95cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 79/80 [00:00<00:00, 107.83cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating prompts for layer 0:   0%|                                                                                                                                                           | 0/80 [00:00<?, ?topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating topic names for layer 0:   0%|                                                                                                                                                       | 0/80 [00:00<?, ?topic/s]\u001b[A\n",
      "Generating topic names for layer 0:   1%|█▊                                                                                                                                             | 1/80 [00:01<01:25,  1.08s/topic]\u001b[A\n",
      "Generating topic names for layer 0:   2%|███▌                                                                                                                                           | 2/80 [00:02<01:17,  1.01topic/s]\u001b[A\n",
      "Generating topic names for layer 0:   4%|█████▎                                                                                                                                         | 3/80 [00:02<01:10,  1.10topic/s]\u001b[A\n",
      "Generating topic names for layer 0:   5%|███████▏                                                                                                                                       | 4/80 [00:03<01:09,  1.09topic/s]\u001b[A\n",
      "Generating topic names for layer 0:   6%|████████▉                                                                                                                                      | 5/80 [00:04<01:03,  1.19topic/s]\u001b[A\n",
      "Generating topic names for layer 0:   8%|██████████▋                                                                                                                                    | 6/80 [00:05<01:17,  1.04s/topic]\u001b[A\n",
      "Generating topic names for layer 0:   9%|████████████▌                                                                                                                                  | 7/80 [00:06<01:09,  1.04topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  10%|██████████████▎                                                                                                                                | 8/80 [00:07<01:09,  1.03topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  11%|████████████████                                                                                                                               | 9/80 [00:08<01:04,  1.10topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  12%|█████████████████▊                                                                                                                            | 10/80 [00:09<01:09,  1.01topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  14%|███████████████████▌                                                                                                                          | 11/80 [00:10<01:08,  1.01topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  15%|█████████████████████▎                                                                                                                        | 12/80 [00:11<01:00,  1.12topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  16%|███████████████████████                                                                                                                       | 13/80 [00:12<00:59,  1.13topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  18%|████████████████████████▊                                                                                                                     | 14/80 [00:13<01:00,  1.09topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  19%|██████████████████████████▋                                                                                                                   | 15/80 [00:13<00:57,  1.13topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  20%|████████████████████████████▍                                                                                                                 | 16/80 [00:14<00:56,  1.14topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  21%|██████████████████████████████▏                                                                                                               | 17/80 [00:16<01:01,  1.02topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  22%|███████████████████████████████▉                                                                                                              | 18/80 [00:16<00:56,  1.10topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  24%|█████████████████████████████████▋                                                                                                            | 19/80 [00:17<01:00,  1.00topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  25%|███████████████████████████████████▌                                                                                                          | 20/80 [00:18<00:55,  1.07topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  26%|█████████████████████████████████████▎                                                                                                        | 21/80 [00:20<01:01,  1.03s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  28%|███████████████████████████████████████                                                                                                       | 22/80 [00:21<01:07,  1.17s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  29%|████████████████████████████████████████▊                                                                                                     | 23/80 [00:22<01:01,  1.09s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  30%|██████████████████████████████████████████▌                                                                                                   | 24/80 [00:23<01:02,  1.12s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  31%|████████████████████████████████████████████▍                                                                                                 | 25/80 [00:24<00:56,  1.03s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  32%|██████████████████████████████████████████████▏                                                                                               | 26/80 [00:25<00:53,  1.00topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  34%|███████████████████████████████████████████████▉                                                                                              | 27/80 [00:26<00:51,  1.02topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  35%|█████████████████████████████████████████████████▋                                                                                            | 28/80 [00:27<00:54,  1.05s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  36%|███████████████████████████████████████████████████▍                                                                                          | 29/80 [00:28<00:51,  1.01s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  38%|█████████████████████████████████████████████████████▎                                                                                        | 30/80 [00:29<00:50,  1.02s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  39%|███████████████████████████████████████████████████████                                                                                       | 31/80 [00:30<00:51,  1.05s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  40%|████████████████████████████████████████████████████████▊                                                                                     | 32/80 [00:31<00:48,  1.01s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  41%|██████████████████████████████████████████████████████████▌                                                                                   | 33/80 [00:32<00:46,  1.02topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  42%|████████████████████████████████████████████████████████████▎                                                                                 | 34/80 [00:33<00:48,  1.06s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  44%|██████████████████████████████████████████████████████████████▏                                                                               | 35/80 [00:34<00:47,  1.05s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  45%|███████████████████████████████████████████████████████████████▉                                                                              | 36/80 [00:35<00:47,  1.07s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  46%|█████████████████████████████████████████████████████████████████▋                                                                            | 37/80 [00:37<00:57,  1.33s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  48%|███████████████████████████████████████████████████████████████████▍                                                                          | 38/80 [00:38<00:53,  1.27s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  49%|█████████████████████████████████████████████████████████████████████▏                                                                        | 39/80 [00:39<00:46,  1.14s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  50%|███████████████████████████████████████████████████████████████████████                                                                       | 40/80 [00:40<00:43,  1.10s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  51%|████████████████████████████████████████████████████████████████████████▊                                                                     | 41/80 [00:41<00:42,  1.08s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  52%|██████████████████████████████████████████████████████████████████████████▌                                                                   | 42/80 [00:42<00:40,  1.06s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  54%|████████████████████████████████████████████████████████████████████████████▎                                                                 | 43/80 [00:43<00:40,  1.11s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  55%|██████████████████████████████████████████████████████████████████████████████                                                                | 44/80 [00:44<00:38,  1.06s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  56%|███████████████████████████████████████████████████████████████████████████████▉                                                              | 45/80 [00:45<00:33,  1.03topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  57%|█████████████████████████████████████████████████████████████████████████████████▋                                                            | 46/80 [00:47<00:37,  1.09s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  59%|███████████████████████████████████████████████████████████████████████████████████▍                                                          | 47/80 [00:48<00:35,  1.09s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  60%|█████████████████████████████████████████████████████████████████████████████████████▏                                                        | 48/80 [00:49<00:32,  1.02s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  61%|██████████████████████████████████████████████████████████████████████████████████████▉                                                       | 49/80 [00:50<00:31,  1.02s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  62%|████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 50/80 [00:50<00:27,  1.08topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  64%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 51/80 [00:51<00:26,  1.11topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  65%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 52/80 [00:52<00:26,  1.05topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  66%|██████████████████████████████████████████████████████████████████████████████████████████████                                                | 53/80 [00:53<00:27,  1.02s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  68%|███████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 54/80 [00:55<00:28,  1.08s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 55/80 [00:57<00:39,  1.57s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  70%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 56/80 [00:59<00:40,  1.67s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 57/80 [01:00<00:33,  1.46s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 58/80 [01:01<00:28,  1.31s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  74%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 59/80 [01:02<00:24,  1.17s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 60/80 [01:03<00:22,  1.11s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 61/80 [01:04<00:18,  1.02topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                | 62/80 [01:04<00:17,  1.05topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 63/80 [01:06<00:17,  1.01s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 64/80 [01:06<00:15,  1.05topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 65/80 [01:08<00:15,  1.02s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 66/80 [01:08<00:13,  1.06topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 67/80 [01:09<00:11,  1.09topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 68/80 [01:10<00:11,  1.03topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 69/80 [01:11<00:10,  1.05topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 70/80 [01:12<00:09,  1.06topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 71/80 [01:13<00:09,  1.00s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 72/80 [01:14<00:08,  1.05s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌            | 73/80 [01:15<00:06,  1.03topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 74/80 [01:16<00:05,  1.08topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 75/80 [01:17<00:05,  1.01s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 76/80 [01:18<00:03,  1.06topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 77/80 [01:19<00:02,  1.05topic/s]\u001b[A\n",
      "Generating topic names for layer 0:  98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 78/80 [01:20<00:02,  1.03s/topic]\u001b[A\n",
      "Generating topic names for layer 0:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 79/80 [01:21<00:00,  1.06topic/s]\u001b[A\n",
      "Generating topic names for layer 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:22<00:00,  1.15topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating disambiguation prompts for layer 0:   0%|                                                                                                                                     | 0/2 [00:00<?, ?topic-cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating new disambiguated topics names for layer 0:   0%|                                                                                                                             | 0/2 [00:00<?, ?topic-cluster/s]\u001b[A\n",
      "Generating new disambiguated topics names for layer 0:  50%|██████████████████████████████████████████████████████████▌                                                          | 1/2 [00:02<00:02,  2.84s/topic-cluster]\u001b[A\n",
      "Generating new disambiguated topics names for layer 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.23s/topic-cluster]\u001b[A\n",
      "Building topic names by layer:  25%|█████████████████████████████████████▎                                                                                                               | 1/4 [01:28<04:24, 88.02s/layer]\u001b[A\n",
      "Selecting facility_location exemplars:   0%|                                                                                                                                                  | 0/26 [00:00<?, ?cluster/s]\u001b[A\n",
      "Selecting facility_location exemplars: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 256.50cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating informative keyphrases:   0%|                                                                                                                                                      | 0/26 [00:00<?, ?cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  31%|███████████████████████████████████████████▋                                                                                                  | 8/26 [00:00<00:00, 73.94cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  65%|████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 17/26 [00:00<00:00, 81.51cluster/s]\u001b[A\n",
      "Generating informative keyphrases: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 79.43cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Selecting facility_location subtopics:   0%|                                                                                                                                                  | 0/26 [00:00<?, ?cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating prompts for layer 1:   0%|                                                                                                                                                           | 0/26 [00:00<?, ?topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating topic names for layer 1:   0%|                                                                                                                                                       | 0/26 [00:00<?, ?topic/s]\u001b[A\n",
      "Generating topic names for layer 1:   4%|█████▌                                                                                                                                         | 1/26 [00:00<00:18,  1.38topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  12%|████████████████▌                                                                                                                              | 3/26 [00:01<00:12,  1.89topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  19%|███████████████████████████▌                                                                                                                   | 5/26 [00:02<00:10,  1.93topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  23%|█████████████████████████████████                                                                                                              | 6/26 [00:03<00:11,  1.70topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  31%|████████████████████████████████████████████                                                                                                   | 8/26 [00:04<00:09,  1.89topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  38%|██████████████████████████████████████████████████████▌                                                                                       | 10/26 [00:05<00:07,  2.12topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  46%|█████████████████████████████████████████████████████████████████▌                                                                            | 12/26 [00:05<00:06,  2.31topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  50%|███████████████████████████████████████████████████████████████████████                                                                       | 13/26 [00:07<00:08,  1.47topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  54%|████████████████████████████████████████████████████████████████████████████▍                                                                 | 14/26 [00:08<00:08,  1.43topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  58%|█████████████████████████████████████████████████████████████████████████████████▉                                                            | 15/26 [00:09<00:07,  1.40topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  62%|███████████████████████████████████████████████████████████████████████████████████████▍                                                      | 16/26 [00:09<00:07,  1.41topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 18/26 [00:10<00:05,  1.48topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                | 20/26 [00:11<00:03,  1.80topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 21/26 [00:12<00:02,  1.69topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                | 23/26 [00:13<00:01,  1.99topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 24/26 [00:14<00:01,  1.47topic/s]\u001b[A\n",
      "Generating topic names for layer 1:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 25/26 [00:15<00:00,  1.46topic/s]\u001b[A\n",
      "Generating topic names for layer 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:16<00:00,  1.37topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A/Users/keyu/miniconda3/envs/toponymy-test/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Building topic names by layer:  50%|██████████████████████████████████████████████████████████████████████████▌                                                                          | 2/4 [01:44<01:32, 46.15s/layer]\n",
      "Selecting facility_location exemplars:   0%|                                                                                                                                                  | 0/10 [00:00<?, ?cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating informative keyphrases:   0%|                                                                                                                                                      | 0/10 [00:00<?, ?cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  70%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 7/10 [00:00<00:00, 63.30cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Selecting facility_location subtopics:   0%|                                                                                                                                                  | 0/10 [00:00<?, ?cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating prompts for layer 2:   0%|                                                                                                                                                           | 0/10 [00:00<?, ?topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating topic names for layer 2:   0%|                                                                                                                                                       | 0/10 [00:00<?, ?topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  10%|██████████████▎                                                                                                                                | 1/10 [00:00<00:07,  1.13topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  40%|█████████████████████████████████████████████████████████▏                                                                                     | 4/10 [00:01<00:02,  2.78topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  50%|███████████████████████████████████████████████████████████████████████▌                                                                       | 5/10 [00:03<00:03,  1.39topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  60%|█████████████████████████████████████████████████████████████████████████████████████▊                                                         | 6/10 [00:04<00:03,  1.29topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  70%|████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 7/10 [00:04<00:02,  1.32topic/s]\u001b[A\n",
      "Generating topic names for layer 2:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                            | 8/10 [00:05<00:01,  1.29topic/s]\u001b[A\n",
      "Generating topic names for layer 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.74topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A/Users/keyu/miniconda3/envs/toponymy-test/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Building topic names by layer:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 3/4 [01:51<00:28, 28.25s/layer]\n",
      "Selecting facility_location exemplars:   0%|                                                                                                                                                   | 0/4 [00:00<?, ?cluster/s]\u001b[A\n",
      "Selecting facility_location exemplars:  50%|█████████████████████████████████████████████████████████████████████▌                                                                     | 2/4 [00:00<00:00, 18.43cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating informative keyphrases:   0%|                                                                                                                                                       | 0/4 [00:00<?, ?cluster/s]\u001b[A\n",
      "Generating informative keyphrases:  50%|███████████████████████████████████████████████████████████████████████▌                                                                       | 2/4 [00:00<00:00, 18.26cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Selecting facility_location subtopics:   0%|                                                                                                                                                   | 0/4 [00:00<?, ?cluster/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating prompts for layer 3:   0%|                                                                                                                                                            | 0/4 [00:00<?, ?topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A\n",
      "Generating topic names for layer 3:   0%|                                                                                                                                                        | 0/4 [00:00<?, ?topic/s]\u001b[A\n",
      "Generating topic names for layer 3:  25%|████████████████████████████████████                                                                                                            | 1/4 [00:00<00:02,  1.18topic/s]\u001b[A\n",
      "Generating topic names for layer 3:  50%|████████████████████████████████████████████████████████████████████████                                                                        | 2/4 [00:01<00:01,  1.20topic/s]\u001b[A\n",
      "                                                                                                                                                                                                                          \u001b[A/Users/keyu/miniconda3/envs/toponymy-test/lib/python3.10/site-packages/torch/nn/modules/module.py:1520: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Building topic names by layer: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:54<00:00, 28.54s/layer]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize clusterer\n",
    "# ToponymyClusterer doesn't have max_clusters parameter, adjust min_clusters and base_min_cluster_size instead\n",
    "clusterer = ToponymyClusterer(min_clusters=3, base_min_cluster_size=10)\n",
    "\n",
    "# Initialize Toponymy\n",
    "topic_model = Toponymy(\n",
    "    llm_wrapper=llm,\n",
    "    text_embedding_model=embedding_model,\n",
    "    clusterer=clusterer,\n",
    "    object_description=\"newsgroup posts\",\n",
    "    corpus_description=\"20-newsgroups dataset\",\n",
    "    exemplar_delimiters=[\"<EXAMPLE_POST>\\n\", \"\\n</EXAMPLE_POST>\\n\\n\"],\n",
    ")\n",
    "\n",
    "print(\"Fitting Toponymy model...\")\n",
    "print(\"This will make API calls to OpenAI - costs will apply!\")\n",
    "topic_model.fit(text_subset, vectors_subset, map_subset)\n",
    "print(\"Model fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 4\n",
      "Layer 0: 80 clusters\n",
      "Layer 1: 26 clusters\n",
      "Layer 2: 10 clusters\n",
      "Layer 3: 4 clusters\n"
     ]
    }
   ],
   "source": [
    "# Show basic model information\n",
    "print(f\"Number of layers: {len(topic_model.cluster_layers_)}\")\n",
    "for i, layer in enumerate(topic_model.cluster_layers_):\n",
    "    n_clusters = len(np.unique(layer.cluster_labels)) - 1  # Exclude -1\n",
    "    print(f\"Layer {i}: {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Audit Functions\n",
    "\n",
    "Now let's test the various audit functions to see intermediate vs final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Layer Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>avg_cluster_size</th>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>max_cluster_size</th>\n",
       "      <th>unique_topic_names</th>\n",
       "      <th>duplicate_topic_names</th>\n",
       "      <th>has_subtopics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>21.925000</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>72.307692</td>\n",
       "      <td>36</td>\n",
       "      <td>146</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>192.100000</td>\n",
       "      <td>118</td>\n",
       "      <td>371</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>579.750000</td>\n",
       "      <td>295</td>\n",
       "      <td>1354</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer  num_clusters  avg_cluster_size  min_cluster_size  max_cluster_size  \\\n",
       "0      0            80         21.925000                10                75   \n",
       "1      1            26         72.307692                36               146   \n",
       "2      2            10        192.100000               118               371   \n",
       "3      3             4        579.750000               295              1354   \n",
       "\n",
       "   unique_topic_names  duplicate_topic_names  has_subtopics  \n",
       "0                  80                      0           True  \n",
       "1                  26                      0           True  \n",
       "2                  10                      0           True  \n",
       "3                   4                      0           True  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get overall layer summary\n",
    "layer_summary = create_layer_summary_df(topic_model)\n",
    "print(\"Layer Summary:\")\n",
    "layer_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Comparison View - Intermediate vs Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Intermediate vs LLM Results (Layer 0, first 10 clusters):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Document Count</th>\n",
       "      <th>Extracted Keyphrases (Top 5)</th>\n",
       "      <th>Exemplar Count</th>\n",
       "      <th>Child Subtopics</th>\n",
       "      <th>Final LLM Topic Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>hockey, game, team, playoffs, players</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>NHL Game Strategies and Player Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>x-soviet armenian government, turkish, muslim ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Armenian-Turkish Conflict and Historical Revis...</td>\n",
       "      <td>Armenian-Turkish Conflict and Historical Revis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>patients, chronic, sci med, msg, intellect and...</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Effects of MSG and Glutamate in Food Co...</td>\n",
       "      <td>Chronic Health Issues and Dietary Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>braves, baseball, catcher, hitter, pinch hit</td>\n",
       "      <td>8</td>\n",
       "      <td>In-Depth Analysis of Phillies and Mariners Pla...</td>\n",
       "      <td>In-Depth Analysis of Phillies and Mariners Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>stats, total baseball, alomar, career, swing</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Evaluation of MLB Player Metrics...</td>\n",
       "      <td>In-depth Analysis of Baseball Player Statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>encryption scheme, clipper chip, public key, k...</td>\n",
       "      <td>8</td>\n",
       "      <td>Mailing List Management and FAQ Discussions in...</td>\n",
       "      <td>Encryption Controversies and Government Survei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>pulse dialing, box and faceplate screw, ground...</td>\n",
       "      <td>8</td>\n",
       "      <td>Telecommunications Equipment and Dialing Techn...</td>\n",
       "      <td>Telecommunications Equipment and Dialing Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>state of israel, arabs, palestinians, jews, ce...</td>\n",
       "      <td>8</td>\n",
       "      <td>Israeli-Palestinian Conflict and Historical Qu...</td>\n",
       "      <td>Israeli-Palestinian Conflict and Holocaust Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>orbit, spacecraft, solar, jupiter, pluto</td>\n",
       "      <td>8</td>\n",
       "      <td>Planetary Exploration Missions and Spacecraft ...</td>\n",
       "      <td>Planetary Exploration Missions and Spacecraft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>space station redesign, moon, space shuttle, s...</td>\n",
       "      <td>8</td>\n",
       "      <td>NASA Space Station Redesign and Lunar Mission ...</td>\n",
       "      <td>NASA Space Station and Astronomy Challenges</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster ID  Document Count  \\\n",
       "0           0             121   \n",
       "1           1              45   \n",
       "2           2             126   \n",
       "3           3              47   \n",
       "4           4              37   \n",
       "5           5             146   \n",
       "6           6              40   \n",
       "7           7              78   \n",
       "8           8              36   \n",
       "9           9              48   \n",
       "\n",
       "                        Extracted Keyphrases (Top 5)  Exemplar Count  \\\n",
       "0              hockey, game, team, playoffs, players               8   \n",
       "1  x-soviet armenian government, turkish, muslim ...               8   \n",
       "2  patients, chronic, sci med, msg, intellect and...               8   \n",
       "3       braves, baseball, catcher, hitter, pinch hit               8   \n",
       "4       stats, total baseball, alomar, career, swing               8   \n",
       "5  encryption scheme, clipper chip, public key, k...               8   \n",
       "6  pulse dialing, box and faceplate screw, ground...               8   \n",
       "7  state of israel, arabs, palestinians, jews, ce...               8   \n",
       "8           orbit, spacecraft, solar, jupiter, pluto               8   \n",
       "9  space station redesign, moon, space shuttle, s...               8   \n",
       "\n",
       "                                     Child Subtopics  \\\n",
       "0  Comprehensive Analysis of NHL Game Outcomes, S...   \n",
       "1  Armenian-Turkish Conflict and Historical Revis...   \n",
       "2  Health Effects of MSG and Glutamate in Food Co...   \n",
       "3  In-Depth Analysis of Phillies and Mariners Pla...   \n",
       "4  Comprehensive Evaluation of MLB Player Metrics...   \n",
       "5  Mailing List Management and FAQ Discussions in...   \n",
       "6  Telecommunications Equipment and Dialing Techn...   \n",
       "7  Israeli-Palestinian Conflict and Historical Qu...   \n",
       "8  Planetary Exploration Missions and Spacecraft ...   \n",
       "9  NASA Space Station Redesign and Lunar Mission ...   \n",
       "\n",
       "                                Final LLM Topic Name  \n",
       "0            NHL Game Strategies and Player Analysis  \n",
       "1  Armenian-Turkish Conflict and Historical Revis...  \n",
       "2          Chronic Health Issues and Dietary Effects  \n",
       "3  In-Depth Analysis of Phillies and Mariners Pla...  \n",
       "4    In-depth Analysis of Baseball Player Statistics  \n",
       "5  Encryption Controversies and Government Survei...  \n",
       "6  Telecommunications Equipment and Dialing Techn...  \n",
       "7  Israeli-Palestinian Conflict and Holocaust Dis...  \n",
       "8  Planetary Exploration Missions and Spacecraft ...  \n",
       "9        NASA Space Station and Astronomy Challenges  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show comparison for layer 0 (most detailed layer)\n",
    "comparison_df = create_comparison_df(topic_model, layer_index=1)\n",
    "print(\"\\nComparison of Intermediate vs LLM Results (Layer 0, first 10 clusters):\")\n",
    "comparison_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison for Layer 2 (broader topics):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Document Count</th>\n",
       "      <th>Extracted Keyphrases (Top 5)</th>\n",
       "      <th>Exemplar Count</th>\n",
       "      <th>Child Subtopics</th>\n",
       "      <th>Final LLM Topic Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>baseball, hitter, hit, braves, players</td>\n",
       "      <td>8</td>\n",
       "      <td>In-Depth Analysis of Phillies and Mariners Pla...</td>\n",
       "      <td>Baseball Player Statistics Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>hockey, team, playoffs, maple leafs, players</td>\n",
       "      <td>8</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>NHL Game Strategies and Player Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>medical, chronic, treatment, intellect and geb...</td>\n",
       "      <td>8</td>\n",
       "      <td>Health Effects of MSG and Glutamate in Food Co...</td>\n",
       "      <td>Chronic Health Issues and Dietary Effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>encryption scheme, clipper chip, security, alg...</td>\n",
       "      <td>8</td>\n",
       "      <td>Telecommunications Equipment and Dialing Techn...</td>\n",
       "      <td>Encryption and Surveillance Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>space station, moon, orbit, solar, mission</td>\n",
       "      <td>8</td>\n",
       "      <td>Planetary Exploration Missions and Spacecraft ...</td>\n",
       "      <td>Space Exploration and Missions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>285</td>\n",
       "      <td>car, bike, oil, engine, honda</td>\n",
       "      <td>8</td>\n",
       "      <td>Chemical Solutions and Practical Applications ...</td>\n",
       "      <td>Automotive and Motorcycling Discussions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>371</td>\n",
       "      <td>video card, ram, windows, dos, local bus</td>\n",
       "      <td>8</td>\n",
       "      <td>Comic Books, CDs, and Movie Merchandise for Sa...</td>\n",
       "      <td>Computer Hardware Discussions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>295</td>\n",
       "      <td>window manager, lib x11, motif, server, widget</td>\n",
       "      <td>8</td>\n",
       "      <td>Discussions on Windows NT, OS/2, and Applicati...</td>\n",
       "      <td>X11 Graphics and Window Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>123</td>\n",
       "      <td>god, bible, sin, christians, heaven</td>\n",
       "      <td>8</td>\n",
       "      <td>Christian Perspectives on Homosexuality and Sc...</td>\n",
       "      <td>Theological Debates on Biblical Interpretation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>151</td>\n",
       "      <td>existence of god, alt atheism, faith, truth, b...</td>\n",
       "      <td>8</td>\n",
       "      <td>Atheism, Religion, and Their Influence on Musi...</td>\n",
       "      <td>Atheism and Religious Debate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster ID  Document Count  \\\n",
       "0           0             140   \n",
       "1           1             121   \n",
       "2           2             126   \n",
       "3           3             191   \n",
       "4           4             118   \n",
       "5           5             285   \n",
       "6           6             371   \n",
       "7           7             295   \n",
       "8           8             123   \n",
       "9           9             151   \n",
       "\n",
       "                        Extracted Keyphrases (Top 5)  Exemplar Count  \\\n",
       "0             baseball, hitter, hit, braves, players               8   \n",
       "1       hockey, team, playoffs, maple leafs, players               8   \n",
       "2  medical, chronic, treatment, intellect and geb...               8   \n",
       "3  encryption scheme, clipper chip, security, alg...               8   \n",
       "4         space station, moon, orbit, solar, mission               8   \n",
       "5                      car, bike, oil, engine, honda               8   \n",
       "6           video card, ram, windows, dos, local bus               8   \n",
       "7     window manager, lib x11, motif, server, widget               8   \n",
       "8                god, bible, sin, christians, heaven               8   \n",
       "9  existence of god, alt atheism, faith, truth, b...               8   \n",
       "\n",
       "                                     Child Subtopics  \\\n",
       "0  In-Depth Analysis of Phillies and Mariners Pla...   \n",
       "1  Comprehensive Analysis of NHL Game Outcomes, S...   \n",
       "2  Health Effects of MSG and Glutamate in Food Co...   \n",
       "3  Telecommunications Equipment and Dialing Techn...   \n",
       "4  Planetary Exploration Missions and Spacecraft ...   \n",
       "5  Chemical Solutions and Practical Applications ...   \n",
       "6  Comic Books, CDs, and Movie Merchandise for Sa...   \n",
       "7  Discussions on Windows NT, OS/2, and Applicati...   \n",
       "8  Christian Perspectives on Homosexuality and Sc...   \n",
       "9  Atheism, Religion, and Their Influence on Musi...   \n",
       "\n",
       "                             Final LLM Topic Name  \n",
       "0             Baseball Player Statistics Analysis  \n",
       "1         NHL Game Strategies and Player Analysis  \n",
       "2       Chronic Health Issues and Dietary Effects  \n",
       "3              Encryption and Surveillance Issues  \n",
       "4                  Space Exploration and Missions  \n",
       "5         Automotive and Motorcycling Discussions  \n",
       "6                   Computer Hardware Discussions  \n",
       "7              X11 Graphics and Window Management  \n",
       "8  Theological Debates on Biblical Interpretation  \n",
       "9                    Atheism and Religious Debate  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show comparison for a higher layer (more general topics)\n",
    "if len(topic_model.cluster_layers_) > 2:\n",
    "    comparison_df_layer2 = create_comparison_df(topic_model, layer_index=2)\n",
    "    print(\"\\nComparison for Layer 2 (broader topics):\")\n",
    "    display(comparison_df_layer2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Detailed Audit DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Audit Information:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_documents</th>\n",
       "      <th>num_keyphrases</th>\n",
       "      <th>num_exemplars</th>\n",
       "      <th>top_5_keyphrases</th>\n",
       "      <th>llm_topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>espn bought, zones abc, hockey games, coverage...</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>det, nhl, saves, 38, stl</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>win game, hawks power, blues, belfour, penalty</td>\n",
       "      <td>In-Depth Discussions on NHL Game Strategies an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>copy protection schemes, pirates, progs, new e...</td>\n",
       "      <td>Discussion on Software Copy Protection and Cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>goalies, tommy soderstrom, curtis joseph, havi...</td>\n",
       "      <td>Discussions on Goalie Equipment and Masks in H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  num_documents  num_keyphrases  num_exemplars  \\\n",
       "0           0             25              16              8   \n",
       "1           1             18              16              8   \n",
       "2           2             25              16              8   \n",
       "3           3             10              16              8   \n",
       "4           4             10              16              8   \n",
       "\n",
       "                                    top_5_keyphrases  \\\n",
       "0  espn bought, zones abc, hockey games, coverage...   \n",
       "1                           det, nhl, saves, 38, stl   \n",
       "2     win game, hawks power, blues, belfour, penalty   \n",
       "3  copy protection schemes, pirates, progs, new e...   \n",
       "4  goalies, tommy soderstrom, curtis joseph, havi...   \n",
       "\n",
       "                                      llm_topic_name  \n",
       "0  NHL Broadcast Coverage and ESPN Scheduling Dis...  \n",
       "1  Comprehensive Analysis of NHL Game Outcomes, S...  \n",
       "2  In-Depth Discussions on NHL Game Strategies an...  \n",
       "3  Discussion on Software Copy Protection and Cir...  \n",
       "4  Discussions on Goalie Equipment and Masks in H...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get detailed audit for layer 0\n",
    "audit_df = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "# Show selected columns for first few clusters\n",
    "print(\"\\nDetailed Audit Information:\")\n",
    "audit_df[['cluster_id', 'num_documents', 'num_keyphrases', 'num_exemplars', \n",
    "          'top_5_keyphrases', 'llm_topic_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed view of Cluster 0:\n",
      "Number of documents: 25\n",
      "\n",
      "Keyphrases extracted: 16\n",
      "Top 5 keyphrases: espn bought, zones abc, hockey games, coverage sunday april, cbc\n",
      "\n",
      "Number of exemplars: 8\n",
      "\n",
      "First exemplar preview:\n",
      "Oh to be back in the good old days when I lived in Florida (Florida for\n",
      "Petes sake!!) and could watch hockey every night as ESPN and USA alternated\n",
      "coverage nights. Oh well I guess it would be too simple for the home office\n",
      "to look back into their past to solve a problem in the present...\n",
      "\n",
      "Of course...\n",
      "\n",
      "Final LLM topic name: 'NHL Broadcast Coverage and ESPN Scheduling Discussions'\n"
     ]
    }
   ],
   "source": [
    "# Look at a specific cluster in detail\n",
    "cluster_to_inspect = 0\n",
    "cluster_audit = audit_df[audit_df['cluster_id'] == cluster_to_inspect].iloc[0]\n",
    "\n",
    "print(f\"\\nDetailed view of Cluster {cluster_to_inspect}:\")\n",
    "print(f\"Number of documents: {cluster_audit['num_documents']}\")\n",
    "print(f\"\\nKeyphrases extracted: {cluster_audit['num_keyphrases']}\")\n",
    "print(f\"Top 5 keyphrases: {cluster_audit['top_5_keyphrases']}\")\n",
    "print(f\"\\nNumber of exemplars: {cluster_audit['num_exemplars']}\")\n",
    "print(f\"\\nFirst exemplar preview:\")\n",
    "print(cluster_audit['first_exemplar'])\n",
    "print(f\"\\nFinal LLM topic name: '{cluster_audit['llm_topic_name']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Keyphrase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyphrase to Topic Name Mapping (first 20):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>keyphrase</th>\n",
       "      <th>llm_topic_name</th>\n",
       "      <th>keyphrase_in_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>espn bought</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>zones abc</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hockey games</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>coverage sunday april</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cbc</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>pm mdt</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>nationwide tsn</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>playoffs</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>satellite dish</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>gary thorne</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>det</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>nhl</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>saves</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>stl</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>tor</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>standings</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>courtnall</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2nd period</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_id              keyphrase  \\\n",
       "0            0            espn bought   \n",
       "1            0              zones abc   \n",
       "2            0           hockey games   \n",
       "3            0  coverage sunday april   \n",
       "4            0                    cbc   \n",
       "5            0                 pm mdt   \n",
       "6            0         nationwide tsn   \n",
       "7            0               playoffs   \n",
       "8            0         satellite dish   \n",
       "9            0            gary thorne   \n",
       "10           1                    det   \n",
       "11           1                    nhl   \n",
       "12           1                  saves   \n",
       "13           1                     38   \n",
       "14           1                    stl   \n",
       "15           1                    tor   \n",
       "16           1                     82   \n",
       "17           1              standings   \n",
       "18           1              courtnall   \n",
       "19           1             2nd period   \n",
       "\n",
       "                                       llm_topic_name  keyphrase_in_topic  \n",
       "0   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "1   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "2   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "3   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "4   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "5   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "6   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "7   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "8   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "9   NHL Broadcast Coverage and ESPN Scheduling Dis...               False  \n",
       "10  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "11  Comprehensive Analysis of NHL Game Outcomes, S...                True  \n",
       "12  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "13  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "14  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "15  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "16  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "17  Comprehensive Analysis of NHL Game Outcomes, S...                True  \n",
       "18  Comprehensive Analysis of NHL Game Outcomes, S...               False  \n",
       "19  Comprehensive Analysis of NHL Game Outcomes, S...               False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyphrase usage in topic names:\n",
      "Keyphrases appearing in topic names: 66\n",
      "Keyphrases NOT in topic names: 734\n",
      "Percentage of keyphrases used: 8.2%\n"
     ]
    }
   ],
   "source": [
    "# Analyze how keyphrases relate to topic names\n",
    "keyphrase_df = create_keyphrase_analysis_df(topic_model, layer_index=0)\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nKeyphrase to Topic Name Mapping (first 20):\")\n",
    "display(keyphrase_df.head(20))\n",
    "\n",
    "# Summary statistics\n",
    "keyphrase_usage = keyphrase_df['keyphrase_in_topic'].value_counts()\n",
    "print(f\"\\nKeyphrase usage in topic names:\")\n",
    "print(f\"Keyphrases appearing in topic names: {keyphrase_usage.get(True, 0)}\")\n",
    "print(f\"Keyphrases NOT in topic names: {keyphrase_usage.get(False, 0)}\")\n",
    "print(f\"Percentage of keyphrases used: {keyphrase_usage.get(True, 0) / len(keyphrase_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Prompt Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt Analysis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>num_exemplars_in_prompt</th>\n",
       "      <th>num_keyphrases_in_prompt</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6010</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15330</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7429</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>In-Depth Discussions on NHL Game Strategies an...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11481</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>Discussion on Software Copy Protection and Cir...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4353</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>Discussions on Goalie Equipment and Masks in H...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7673</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>NHL European Player Representation and Managem...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12104</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>NCAA Hockey Discussions and Coaching Changes i...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6773</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>NHL Trades, Strategies, and Player Prospects D...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13293</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>Youth Drug Use, Health Insurance, and Poverty ...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8161</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>Engineering Challenges in Fossil Fuel Plants a...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer  cluster_id  prompt_length  num_exemplars_in_prompt  \\\n",
       "0      0           0           6010                       16   \n",
       "1      0           1          15330                       16   \n",
       "2      0           2           7429                       16   \n",
       "3      0           3          11481                       16   \n",
       "4      0           4           4353                       16   \n",
       "5      0           5           7673                       16   \n",
       "6      0           6          12104                       16   \n",
       "7      0           7           6773                       16   \n",
       "8      0           8          13293                       16   \n",
       "9      0           9           8161                       16   \n",
       "\n",
       "   num_keyphrases_in_prompt  \\\n",
       "0                        10   \n",
       "1                        10   \n",
       "2                        10   \n",
       "3                        10   \n",
       "4                        10   \n",
       "5                        10   \n",
       "6                        10   \n",
       "7                        10   \n",
       "8                        10   \n",
       "9                        10   \n",
       "\n",
       "                                          topic_name  topic_name_length  \n",
       "0  NHL Broadcast Coverage and ESPN Scheduling Dis...                 54  \n",
       "1  Comprehensive Analysis of NHL Game Outcomes, S...                 74  \n",
       "2  In-Depth Discussions on NHL Game Strategies an...                 75  \n",
       "3  Discussion on Software Copy Protection and Cir...                 67  \n",
       "4  Discussions on Goalie Equipment and Masks in H...                 51  \n",
       "5  NHL European Player Representation and Managem...                 58  \n",
       "6  NCAA Hockey Discussions and Coaching Changes i...                 66  \n",
       "7  NHL Trades, Strategies, and Player Prospects D...                 56  \n",
       "8  Youth Drug Use, Health Insurance, and Poverty ...                 64  \n",
       "9  Engineering Challenges in Fossil Fuel Plants a...                 77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt Statistics:\n",
      "Average prompt length: 9864 characters\n",
      "Min prompt length: 39\n",
      "Max prompt length: 33518\n",
      "\n",
      "Average topic name length: 56.6 characters\n"
     ]
    }
   ],
   "source": [
    "# Analyze prompts sent to LLM\n",
    "prompt_df = create_prompt_analysis_df(topic_model)\n",
    "\n",
    "print(\"\\nPrompt Analysis:\")\n",
    "display(prompt_df.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nPrompt Statistics:\")\n",
    "print(f\"Average prompt length: {prompt_df['prompt_length'].mean():.0f} characters\")\n",
    "print(f\"Min prompt length: {prompt_df['prompt_length'].min()}\")\n",
    "print(f\"Max prompt length: {prompt_df['prompt_length'].max()}\")\n",
    "print(f\"\\nAverage topic name length: {prompt_df['topic_name_length'].mean():.1f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Get Full Details for a Specific Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete Cluster Details:\n",
      "Layer: 0\n",
      "Cluster ID: 0\n",
      "Number of documents: 25\n",
      "Topic name: NHL Broadcast Coverage and ESPN Scheduling Discussions\n",
      "\n",
      "Keyphrases (top 10): ['espn bought', 'zones abc', 'hockey games', 'coverage sunday april', 'cbc', 'pm mdt', 'nationwide tsn', 'playoffs', 'satellite dish', 'gary thorne']\n",
      "\n",
      "Number of exemplars: 8\n",
      "\n",
      "Prompt sent to LLM (first 1000 chars):\n",
      "{'system': '\\nYou are an expert at classifying newsgroup posts from 20-newsgroups dataset into topics.\\nYour task is to analyze information about a group of newsgroup posts and assign a domain expert level (8 to 15 word) name to this group.\\nThe response must be in JSON formatted as {\"topic_name\":<NAME>, \"topic_specificity\":<SCORE>}\\nwhere NAME is the topic name you generate and SCORE is a float value between 0.0 and 1.0,\\nrepresenting how specific and well-defined the topic name is given the input information.\\nA score of 1.0 means a perfectly descriptive and specific name, while 0.0 would be a completely generic or unrelated name.\\n\\n\\nEnsure your entire response is only the JSON object, with no other text before or after it.', 'user': '\\nHere is the information about the group of newsgroup posts:\\n\\n- Keywords for this group include: espn bought, zones abc, hockey games, coverage sunday april, cbc, pm mdt, nationwide tsn, playoffs, satellite dish, gary thorne, clement, 30 edt nation...\n"
     ]
    }
   ],
   "source": [
    "# Get complete details for a specific cluster including the actual prompt\n",
    "cluster_details = get_cluster_details(topic_model, layer_index=0, cluster_id=0)\n",
    "\n",
    "print(\"\\nComplete Cluster Details:\")\n",
    "print(f\"Layer: {cluster_details['layer']}\")\n",
    "print(f\"Cluster ID: {cluster_details['cluster_id']}\")\n",
    "print(f\"Number of documents: {cluster_details['num_documents']}\")\n",
    "print(f\"Topic name: {cluster_details['topic_name']}\")\n",
    "\n",
    "print(f\"\\nKeyphrases (top 10): {cluster_details['keyphrases'][:10]}\")\n",
    "print(f\"\\nNumber of exemplars: {len(cluster_details['exemplars'])}\")\n",
    "\n",
    "if 'prompt' in cluster_details:\n",
    "    print(f\"\\nPrompt sent to LLM (first 1000 chars):\")\n",
    "    print(str(cluster_details['prompt'])[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export all audit data to Excel file\n",
    "# export_audit_excel(topic_model, \"toponymy_audit_report.xlsx\")\n",
    "# print(\"\\nExcel file created with multiple sheets containing all audit data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Audit Results\n",
    "\n",
    "Let's create some visualizations to better understand the relationship between intermediate and final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Set style\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster sizes across layers\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "layer_summary = create_layer_summary_df(topic_model)\n",
    "x = layer_summary['layer']\n",
    "y = layer_summary['num_clusters']\n",
    "\n",
    "ax.bar(x, y)\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Number of Clusters')\n",
    "ax.set_title('Number of Clusters per Layer')\n",
    "ax.set_xticks(x)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(i, v + 0.5, str(v), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between prompt length and topic name length\n",
    "prompt_df = create_prompt_analysis_df(topic_model)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "scatter = ax.scatter(prompt_df['prompt_length'], \n",
    "                    prompt_df['topic_name_length'],\n",
    "                    c=prompt_df['layer'],\n",
    "                    cmap='viridis',\n",
    "                    alpha=0.6,\n",
    "                    s=50)\n",
    "\n",
    "ax.set_xlabel('Prompt Length (characters)')\n",
    "ax.set_ylabel('Topic Name Length (characters)')\n",
    "ax.set_title('Prompt Length vs Topic Name Length')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Layer')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of cluster sizes\n",
    "audit_df = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(audit_df['num_documents'], bins=30, edgecolor='black')\n",
    "ax.set_xlabel('Number of Documents')\n",
    "ax.set_ylabel('Number of Clusters')\n",
    "ax.set_title('Distribution of Cluster Sizes (Layer 0)')\n",
    "ax.axvline(audit_df['num_documents'].mean(), color='red', linestyle='--', \n",
    "           label=f'Mean: {audit_df[\"num_documents\"].mean():.1f}')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Use Cases for Auditing\n",
    "\n",
    "Here are some practical examples of how to use the audit functionality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Find clusters where keyphrases don't match topic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 clusters where top keyphrases don't appear in topic name:\n",
      "\n",
      "Cluster 0 (25 docs):\n",
      "  Keyphrases: espn bought, zones abc, hockey games, coverage sunday april, cbc\n",
      "  Topic name: NHL Broadcast Coverage and ESPN Scheduling Discussions\n",
      "\n",
      "Cluster 2 (25 docs):\n",
      "  Keyphrases: win game, hawks power, blues, belfour, penalty\n",
      "  Topic name: In-Depth Discussions on NHL Game Strategies and Player Performance Insights\n",
      "\n",
      "Cluster 6 (12 docs):\n",
      "  Keyphrases: mike keenan, ncaa division hockey, maine black bears, laughter senator mitchell, flyers\n",
      "  Topic name: NCAA Hockey Discussions and Coaching Changes in Professional Teams\n",
      "\n",
      "Cluster 7 (15 docs):\n",
      "  Keyphrases: daigle, sharks, sather, kozlov, previous gm\n",
      "  Topic name: NHL Trades, Strategies, and Player Prospects Discussions\n",
      "\n",
      "Cluster 9 (13 docs):\n",
      "  Keyphrases: fossil plants, radar detector detectors, cooling towers, hotwell pumps, condenser tubes\n",
      "  Topic name: Engineering Challenges in Fossil Fuel Plants and Radar Detection Technologies\n"
     ]
    }
   ],
   "source": [
    "# Find potential mismatches\n",
    "audit_df = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "# Check if any top keyphrases appear in the topic name\n",
    "mismatches = []\n",
    "for _, row in audit_df.iterrows():\n",
    "    top_keyphrases = row['top_5_keyphrases'].lower().split(', ')\n",
    "    topic_name = row['llm_topic_name'].lower()\n",
    "    \n",
    "    # Check if any keyphrase appears in topic name\n",
    "    match_found = any(kp in topic_name for kp in top_keyphrases if kp)\n",
    "    \n",
    "    if not match_found and row['num_documents'] > 10:  # Only consider clusters with >10 docs\n",
    "        mismatches.append({\n",
    "            'cluster_id': row['cluster_id'],\n",
    "            'keyphrases': row['top_5_keyphrases'],\n",
    "            'topic_name': row['llm_topic_name'],\n",
    "            'num_docs': row['num_documents']\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(mismatches)} clusters where top keyphrases don't appear in topic name:\")\n",
    "for m in mismatches[:5]:  # Show first 5\n",
    "    print(f\"\\nCluster {m['cluster_id']} ({m['num_docs']} docs):\")\n",
    "    print(f\"  Keyphrases: {m['keyphrases']}\")\n",
    "    print(f\"  Topic name: {m['topic_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Find duplicate topic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate topic names within each layer\n",
    "for layer_idx in range(len(topic_model.cluster_layers_)):\n",
    "    layer = topic_model.cluster_layers_[layer_idx]\n",
    "    topic_counts = pd.Series(layer.topic_names).value_counts()\n",
    "    duplicates = topic_counts[topic_counts > 1]\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"\\nLayer {layer_idx} - Duplicate topic names:\")\n",
    "        for topic, count in duplicates.items():\n",
    "            print(f\"  '{topic}' appears {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Analyze topic quality by cluster size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small clusters (<20 docs):\n",
      "  Count: 46\n",
      "  Avg keyphrases: 16.0\n",
      "  Avg topic name length: 63.6\n",
      "\n",
      "Large clusters (>100 docs):\n",
      "  Count: 0\n",
      "  Avg keyphrases: nan\n",
      "  Avg topic name length: nan\n",
      "\n",
      "Example small cluster topics:\n",
      "  - Comprehensive Analysis of NHL Game Outcomes, Standings, and Player Metrics (18 docs)\n",
      "  - Discussion on Software Copy Protection and Circumvention Techniques (10 docs)\n",
      "  - Discussions on Goalie Equipment and Masks in Hockey (10 docs)\n",
      "\n",
      "Example large cluster topics:\n"
     ]
    }
   ],
   "source": [
    "# Compare small vs large clusters\n",
    "audit_df = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "# Define small and large clusters\n",
    "small_clusters = audit_df[audit_df['num_documents'] < 20]\n",
    "large_clusters = audit_df[audit_df['num_documents'] > 100]\n",
    "\n",
    "print(\"Small clusters (<20 docs):\")\n",
    "print(f\"  Count: {len(small_clusters)}\")\n",
    "print(f\"  Avg keyphrases: {small_clusters['num_keyphrases'].mean():.1f}\")\n",
    "print(f\"  Avg topic name length: {small_clusters['llm_topic_name'].str.len().mean():.1f}\")\n",
    "\n",
    "print(\"\\nLarge clusters (>100 docs):\")\n",
    "print(f\"  Count: {len(large_clusters)}\")\n",
    "print(f\"  Avg keyphrases: {large_clusters['num_keyphrases'].mean():.1f}\")\n",
    "print(f\"  Avg topic name length: {large_clusters['llm_topic_name'].str.len().mean():.1f}\")\n",
    "\n",
    "print(\"\\nExample small cluster topics:\")\n",
    "for _, row in small_clusters.head(3).iterrows():\n",
    "    print(f\"  - {row['llm_topic_name']} ({row['num_documents']} docs)\")\n",
    "\n",
    "print(\"\\nExample large cluster topics:\")\n",
    "for _, row in large_clusters.head(3).iterrows():\n",
    "    print(f\"  - {row['llm_topic_name']} ({row['num_documents']} docs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The audit functionality provides several ways to inspect and validate Toponymy results:\n",
    "\n",
    "1. **`create_audit_df()`** - Get comprehensive audit data as a DataFrame\n",
    "2. **`create_comparison_df()`** - Simple side-by-side comparison of intermediate vs final results\n",
    "3. **`create_keyphrase_analysis_df()`** - Analyze how keyphrases relate to topic names\n",
    "4. **`create_layer_summary_df()`** - High-level statistics for each layer\n",
    "5. **`create_prompt_analysis_df()`** - Analyze prompt characteristics\n",
    "6. **`get_cluster_details()`** - Get all details for a specific cluster\n",
    "7. **`export_audit_excel()`** - Export everything to Excel for further analysis\n",
    "\n",
    "This allows you to:\n",
    "- Verify that topic names accurately reflect the extracted keyphrases and exemplars\n",
    "- Identify potential issues or mismatches\n",
    "- Understand how the LLM is interpreting the intermediate data\n",
    "- Debug and improve your topic modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Intermediate vs LLM Results (Layer 0, first 10 clusters):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster ID</th>\n",
       "      <th>Document Count</th>\n",
       "      <th>Extracted Keyphrases (Top 5)</th>\n",
       "      <th>Exemplar Count</th>\n",
       "      <th>Child Subtopics</th>\n",
       "      <th>Final LLM Topic Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>espn bought, zones abc, hockey games, coverage...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>NHL Broadcast Coverage and ESPN Scheduling Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>det, nhl, saves, 38, stl</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>win game, hawks power, blues, belfour, penalty</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>In-Depth Discussions on NHL Game Strategies an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>copy protection schemes, pirates, progs, new e...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Discussion on Software Copy Protection and Cir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>goalies, tommy soderstrom, curtis joseph, havi...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Discussions on Goalie Equipment and Masks in H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>nhl teams, classy, numbers of euros, names lik...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>NHL European Player Representation and Managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>mike keenan, ncaa division hockey, maine black...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>NCAA Hockey Discussions and Coaching Changes i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>daigle, sharks, sather, kozlov, previous gm</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>NHL Trades, Strategies, and Player Prospects D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>health insurance plan providing, drugs, lsd an...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Youth Drug Use, Health Insurance, and Poverty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>fossil plants, radar detector detectors, cooli...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Engineering Challenges in Fossil Fuel Plants a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster ID  Document Count  \\\n",
       "0           0              25   \n",
       "1           1              18   \n",
       "2           2              25   \n",
       "3           3              10   \n",
       "4           4              10   \n",
       "5           5              10   \n",
       "6           6              12   \n",
       "7           7              15   \n",
       "8           8              10   \n",
       "9           9              13   \n",
       "\n",
       "                        Extracted Keyphrases (Top 5)  Exemplar Count  \\\n",
       "0  espn bought, zones abc, hockey games, coverage...               8   \n",
       "1                           det, nhl, saves, 38, stl               8   \n",
       "2     win game, hawks power, blues, belfour, penalty               8   \n",
       "3  copy protection schemes, pirates, progs, new e...               8   \n",
       "4  goalies, tommy soderstrom, curtis joseph, havi...               8   \n",
       "5  nhl teams, classy, numbers of euros, names lik...               8   \n",
       "6  mike keenan, ncaa division hockey, maine black...               8   \n",
       "7        daigle, sharks, sather, kozlov, previous gm               8   \n",
       "8  health insurance plan providing, drugs, lsd an...               8   \n",
       "9  fossil plants, radar detector detectors, cooli...               8   \n",
       "\n",
       "  Child Subtopics                               Final LLM Topic Name  \n",
       "0                  NHL Broadcast Coverage and ESPN Scheduling Dis...  \n",
       "1                  Comprehensive Analysis of NHL Game Outcomes, S...  \n",
       "2                  In-Depth Discussions on NHL Game Strategies an...  \n",
       "3                  Discussion on Software Copy Protection and Cir...  \n",
       "4                  Discussions on Goalie Equipment and Masks in H...  \n",
       "5                  NHL European Player Representation and Managem...  \n",
       "6                  NCAA Hockey Discussions and Coaching Changes i...  \n",
       "7                  NHL Trades, Strategies, and Player Prospects D...  \n",
       "8                  Youth Drug Use, Health Insurance, and Poverty ...  \n",
       "9                  Engineering Challenges in Fossil Fuel Plants a...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = create_comparison_df(topic_model, layer_index=0)\n",
    "print(\"\\nComparison of Intermediate vs LLM Results (Layer 0, first 10 clusters):\")\n",
    "comparison_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original text subset for testing new functionality\n",
    "original_texts = text_subset.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing New Document Traceability Features\n",
    "\n",
    "The audit functionality now includes the ability to trace back to original documents. Let's test these new features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Basic Document Indices (Always Included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document indices for each cluster (Layer 0):\n",
      "\n",
      "Cluster 0: NHL Broadcast Coverage and ESPN Scheduling Discussions\n",
      "  Number of documents: 25\n",
      "  Document indices: [7, 79, 103, 220, 649, 751, 765, 1086, 1118, 1239, 1358, 1435, 1649, 1701, 1718, 1799, 1934, 1998, 2212, 2508, 2565, 2642, 2755, 2811, 2935]\n",
      "  Sample documents:\n",
      "    [7] [stuff deleted]\n",
      "\n",
      "Ok, here's the solution to your problem.  Move to Canada.  Yest...\n",
      "    [79] Well I think whenever ESPN covers the game they do a wonderful job. But\n",
      "   what ...\n",
      "\n",
      "Cluster 1: Comprehensive Analysis of NHL Game Outcomes, Standings, and Player Metrics\n",
      "  Number of documents: 18\n",
      "  Document indices: [44, 76, 211, 370, 537, 609, 642, 794, 946, 950, 994, 1151, 1708, 2220, 2343, 2374, 2523, 2902]\n",
      "  Sample documents:\n",
      "    [44] Here are the NHL's alltime leaders in goals and points at the end of\n",
      "the 1992-3 ...\n",
      "    [76] Why not? I believe both the Devils and Islanders got 87 points.\n",
      "Say for example,...\n",
      "\n",
      "Cluster 2: In-Depth Discussions on NHL Game Strategies and Player Performance Insights\n",
      "  Number of documents: 25\n",
      "  Document indices: [0, 174, 574, 718, 850, 933, 972, 1149, 1254, 1263, 1577, 1606, 1620, 1689, 1749, 1813, 1842, 1974, 2083, 2206, 2607, 2613, 2768, 2826, 2989]\n",
      "  Sample documents:\n",
      "    [0] I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any ki...\n",
      "    [174] Dear Ulf,\n",
      "\n",
      "\tWould you possibly consider helpiMontreal Canadiens fans everywhere\n",
      "...\n",
      "\n",
      "Cluster 3: Discussion on Software Copy Protection and Circumvention Techniques\n",
      "  Number of documents: 10\n",
      "  Document indices: [200, 546, 789, 1446, 1458, 1737, 2080, 2417, 2879, 2929]\n",
      "  Sample documents:\n",
      "    [200] One of the easiest, and really very used ways of copyprotection, is to mark \n",
      "a s...\n",
      "    [546] WHAT??!!!!\n",
      "\n",
      "You can't remove it, unless you register?  \n",
      "You gotta be joking, rig...\n",
      "\n",
      "Cluster 4: Discussions on Goalie Equipment and Masks in Hockey\n",
      "  Number of documents: 10\n",
      "  Document indices: [8, 96, 544, 687, 908, 1700, 1880, 1890, 2127, 2424]\n",
      "  Sample documents:\n",
      "    [8] Yeah, it's the second one.  And I believe that price too.  I've been trying\n",
      "to g...\n",
      "    [96] Hey man! -\n",
      "\n",
      "Having spent the past season learning to skate and having played a\n",
      "c...\n"
     ]
    }
   ],
   "source": [
    "# Create audit DataFrame - document_indices are now always included\n",
    "audit_with_indices = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "# Show document indices for each cluster\n",
    "print(\"Document indices for each cluster (Layer 0):\")\n",
    "for idx, row in audit_with_indices.head(5).iterrows():\n",
    "    print(f\"\\nCluster {row['cluster_id']}: {row['llm_topic_name']}\")\n",
    "    print(f\"  Number of documents: {row['num_documents']}\")\n",
    "    print(f\"  Document indices: {row['document_indices']}\")\n",
    "    \n",
    "    # Show a few document texts from the indices\n",
    "    print(f\"  Sample documents:\")\n",
    "    for doc_idx in row['document_indices'][:2]:  # Show first 2 documents\n",
    "        print(f\"    [{doc_idx}] {original_texts[doc_idx][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Full Document Texts in Audit DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: NHL Game Strategies and Player Analysis\n",
      "Keyphrases: hockey, game, team, playoffs, players\n",
      "\n",
      "All 121 documents in this cluster:\n",
      "\n",
      "[Document 0]:\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I...\n",
      "\n",
      "[Document 8]:\n",
      "Yeah, it's the second one.  And I believe that price too.  I've been trying\n",
      "to get a good look at it on the Bruin-Sabre telecasts, and wow! does it ever\n",
      "look good.  Whoever did that paint job knew wha...\n",
      "\n",
      "[Document 24]:\n",
      "I don't know the exact coverage in the states.  In Canada it is covered\n",
      "by TSN, so maybe ESPN will grab their coverage!  I don't know!\n",
      "\n",
      "As for the picks\n",
      "Ottawa picks #1 which means it is almost 100% t...\n",
      "\n",
      "... and 118 more documents\n"
     ]
    }
   ],
   "source": [
    "# Create audit with full document texts\n",
    "audit_with_docs = create_audit_df(\n",
    "    topic_model, \n",
    "    layer_index=1,\n",
    "    include_all_docs=True,\n",
    "    original_texts=original_texts\n",
    ")\n",
    "\n",
    "# Show the first cluster with all its documents\n",
    "first_cluster = audit_with_docs.iloc[0]\n",
    "print(f\"Cluster 0: {first_cluster['llm_topic_name']}\")\n",
    "print(f\"Keyphrases: {first_cluster['top_5_keyphrases']}\")\n",
    "print(f\"\\nAll {first_cluster['num_documents']} documents in this cluster:\")\n",
    "\n",
    "if 'document_texts' in first_cluster:\n",
    "    for i, (idx, doc) in enumerate(zip(first_cluster['document_indices'], first_cluster['document_texts'])):\n",
    "        print(f\"\\n[Document {idx}]:\")\n",
    "        print(doc[:200] + \"...\" if len(doc) > 200 else doc)\n",
    "        if i >= 2:  # Show only first 3 documents\n",
    "            print(f\"\\n... and {len(first_cluster['document_texts']) - 3} more documents\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_documents</th>\n",
       "      <th>top_5_keyphrases</th>\n",
       "      <th>all_keyphrases</th>\n",
       "      <th>num_keyphrases</th>\n",
       "      <th>num_exemplars</th>\n",
       "      <th>first_exemplar</th>\n",
       "      <th>subtopics_list</th>\n",
       "      <th>subtopics_text</th>\n",
       "      <th>prompt_preview</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>llm_topic_name</th>\n",
       "      <th>document_indices</th>\n",
       "      <th>document_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>hockey, game, team, playoffs, players</td>\n",
       "      <td>[hockey, game, team, playoffs, players, leafs,...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>NHL RESULTS FOR GAMES PLAYED 4/15/93.\\n\\n-----...</td>\n",
       "      <td>[Comprehensive Analysis of NHL Game Outcomes, ...</td>\n",
       "      <td>Comprehensive Analysis of NHL Game Outcomes, S...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>19817</td>\n",
       "      <td>NHL Game Strategies and Player Analysis</td>\n",
       "      <td>[0, 8, 24, 44, 66, 76, 96, 130, 174, 211, 228,...</td>\n",
       "      <td>[I am sure some bashers of Pens fans are prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>x-soviet armenian government, turkish, muslim ...</td>\n",
       "      <td>[x-soviet armenian government, turkish, muslim...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Turkish Historical Revision &lt;9305111942@zuma.U...</td>\n",
       "      <td>[Armenian-Turkish Conflict and Historical Revi...</td>\n",
       "      <td>Armenian-Turkish Conflict and Historical Revis...</td>\n",
       "      <td>[!SKIP!]: Armenian-Turkish Conflict and Histor...</td>\n",
       "      <td>78</td>\n",
       "      <td>Armenian-Turkish Conflict and Historical Revis...</td>\n",
       "      <td>[2, 15, 64, 93, 112, 113, 182, 188, 265, 304, ...</td>\n",
       "      <td>[Finally you said what you dream about. Medite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>patients, chronic, sci med, msg, intellect and...</td>\n",
       "      <td>[patients, chronic, sci med, msg, intellect an...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Hate to wreck your elaborate theory, but Steve...</td>\n",
       "      <td>[Health Effects of MSG and Glutamate in Food C...</td>\n",
       "      <td>Health Effects of MSG and Glutamate in Food Co...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>9422</td>\n",
       "      <td>Chronic Health Issues and Dietary Effects</td>\n",
       "      <td>[34, 164, 190, 233, 253, 263, 269, 303, 337, 3...</td>\n",
       "      <td>[According to a previous poster, one should se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>braves, baseball, catcher, hitter, pinch hit</td>\n",
       "      <td>[braves, baseball, catcher, hitter, pinch hit,...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>HEY!!! All you Yankee fans who've been knockin...</td>\n",
       "      <td>[In-Depth Analysis of Phillies and Mariners Pl...</td>\n",
       "      <td>In-Depth Analysis of Phillies and Mariners Pla...</td>\n",
       "      <td>[!SKIP!]: In-Depth Analysis of Phillies and Ma...</td>\n",
       "      <td>78</td>\n",
       "      <td>In-Depth Analysis of Phillies and Mariners Pla...</td>\n",
       "      <td>[33, 144, 171, 318, 371, 378, 458, 470, 802, 9...</td>\n",
       "      <td>[Be patient. He has a sore shoulder from crash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>stats, total baseball, alomar, career, swing</td>\n",
       "      <td>[stats, total baseball, alomar, career, swing,...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>You're right: Thomas, Gonzalez, Sheffield, and...</td>\n",
       "      <td>[Comprehensive Evaluation of MLB Player Metric...</td>\n",
       "      <td>Comprehensive Evaluation of MLB Player Metrics...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>8872</td>\n",
       "      <td>In-depth Analysis of Baseball Player Statistics</td>\n",
       "      <td>[60, 90, 116, 225, 379, 395, 497, 509, 557, 64...</td>\n",
       "      <td>[I don't buy this at all.  I think things are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>encryption scheme, clipper chip, public key, k...</td>\n",
       "      <td>[encryption scheme, clipper chip, public key, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>^^^^^^^^^^^^^^^^^^^\\\\n                        ...</td>\n",
       "      <td>[Mailing List Management and FAQ Discussions i...</td>\n",
       "      <td>Mailing List Management and FAQ Discussions in...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>22347</td>\n",
       "      <td>Encryption Controversies and Government Survei...</td>\n",
       "      <td>[48, 53, 73, 133, 140, 141, 169, 215, 217, 224...</td>\n",
       "      <td>[You're blowing smoke.  Qualcomm wants to sell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>pulse dialing, box and faceplate screw, ground...</td>\n",
       "      <td>[pulse dialing, box and faceplate screw, groun...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey Serdar,\\n           What nationality are y...</td>\n",
       "      <td>[Telecommunications Equipment and Dialing Tech...</td>\n",
       "      <td>Telecommunications Equipment and Dialing Techn...</td>\n",
       "      <td>[!SKIP!]: Telecommunications Equipment and Dia...</td>\n",
       "      <td>73</td>\n",
       "      <td>Telecommunications Equipment and Dialing Techn...</td>\n",
       "      <td>[6, 49, 78, 88, 98, 198, 285, 334, 524, 568, 6...</td>\n",
       "      <td>[AE is in Dallas...try 214/241-6060 or 214/241...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>state of israel, arabs, palestinians, jews, ce...</td>\n",
       "      <td>[state of israel, arabs, palestinians, jews, c...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Elias Davidsson writes...\\n \\n \\nED&gt; The follo...</td>\n",
       "      <td>[Israeli-Palestinian Conflict and Historical Q...</td>\n",
       "      <td>Israeli-Palestinian Conflict and Historical Qu...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>22035</td>\n",
       "      <td>Israeli-Palestinian Conflict and Holocaust Dis...</td>\n",
       "      <td>[102, 153, 274, 332, 339, 415, 510, 559, 567, ...</td>\n",
       "      <td>[In the same way in which antisemite means ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>orbit, spacecraft, solar, jupiter, pluto</td>\n",
       "      <td>[orbit, spacecraft, solar, jupiter, pluto, pro...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Archive-name: space/new_probes\\nLast-modified:...</td>\n",
       "      <td>[Planetary Exploration Missions and Spacecraft...</td>\n",
       "      <td>Planetary Exploration Missions and Spacecraft ...</td>\n",
       "      <td>[!SKIP!]: Planetary Exploration Missions and S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Planetary Exploration Missions and Spacecraft ...</td>\n",
       "      <td>[14, 40, 210, 234, 296, 324, 479, 489, 698, 78...</td>\n",
       "      <td>[There is no notion of heliocentric, or even g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>space station redesign, moon, space shuttle, s...</td>\n",
       "      <td>[space station redesign, moon, space shuttle, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>In the April edition of \"One Small Step for a ...</td>\n",
       "      <td>[NASA Space Station Redesign and Lunar Mission...</td>\n",
       "      <td>NASA Space Station Redesign and Lunar Mission ...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>18020</td>\n",
       "      <td>NASA Space Station and Astronomy Challenges</td>\n",
       "      <td>[110, 154, 311, 322, 375, 437, 506, 514, 581, ...</td>\n",
       "      <td>[\"Space Station Redesign Leader Says Cost Goal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>objective morality, hudson me hudson, science ...</td>\n",
       "      <td>[objective morality, hudson me hudson, science...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>I think that you are changing the meaning of \"...</td>\n",
       "      <td>[Debate on Objective Morality and Its Empirica...</td>\n",
       "      <td>Debate on Objective Morality and Its Empirical...</td>\n",
       "      <td>[!SKIP!]: Debate on Objective Morality and Its...</td>\n",
       "      <td>68</td>\n",
       "      <td>Debate on Objective Morality and Its Empirical...</td>\n",
       "      <td>[29, 216, 275, 305, 343, 389, 438, 459, 464, 6...</td>\n",
       "      <td>[[ . . .]\\n\\nI am a relativist who would like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>non-toxic tear gas, fbi thought, propane, fume...</td>\n",
       "      <td>[non-toxic tear gas, fbi thought, propane, fum...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Flash over is a frequent occurrence with indoo...</td>\n",
       "      <td>[Waco Siege: Tear Gas, Fire, and Government Ac...</td>\n",
       "      <td>Waco Siege: Tear Gas, Fire, and Government Acc...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>9708</td>\n",
       "      <td>Waco Siege: Chemical Exposure and Fire Risks</td>\n",
       "      <td>[17, 26, 97, 207, 247, 401, 423, 543, 582, 881...</td>\n",
       "      <td>[.........\\nI, some years ago, almost became a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "      <td>batf agents, david koresh, compound, did the f...</td>\n",
       "      <td>[batf agents, david koresh, compound, did the ...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>A few comments on the ATF's botched handling o...</td>\n",
       "      <td>[Waco Siege and Government Response to Branch ...</td>\n",
       "      <td>Waco Siege and Government Response to Branch D...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>10702</td>\n",
       "      <td>Waco Siege and Branch Davidian Controversies</td>\n",
       "      <td>[31, 52, 129, 280, 306, 315, 321, 336, 353, 38...</td>\n",
       "      <td>[The explanations of Federal law enforcement o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>tape drive, scsi controller, ide drives, hd, dma</td>\n",
       "      <td>[tape drive, scsi controller, ide drives, hd, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>I have had a SCSI and IDE drive working togeth...</td>\n",
       "      <td>[SCSI and IDE Storage Technologies for Mac and...</td>\n",
       "      <td>SCSI and IDE Storage Technologies for Mac and ...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>7629</td>\n",
       "      <td>Hard Disk and Storage Technology Discussions</td>\n",
       "      <td>[3, 4, 16, 134, 148, 213, 248, 277, 307, 317, ...</td>\n",
       "      <td>[Think!\\n\\nIt's the SCSI card doing the DMA tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>amp, voltage, stereo, receiver, baden sys6626</td>\n",
       "      <td>[amp, voltage, stereo, receiver, baden sys6626...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>FOR SALE!!!!\\n\\n1) Sony Car Stereo Amplifier (...</td>\n",
       "      <td>[Audio Equipment Sales and Electronic Measurem...</td>\n",
       "      <td>Audio Equipment Sales and Electronic Measureme...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>8282</td>\n",
       "      <td>Audio Equipment Sales and Signal Measurement</td>\n",
       "      <td>[47, 50, 65, 115, 125, 157, 163, 178, 189, 236...</td>\n",
       "      <td>[Counterpoint  SA-12\\n\\n85watts per channel\\nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>bike, honda, ride, lane, cars</td>\n",
       "      <td>[bike, honda, ride, lane, cars, biker dod 1069...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Sixteen days I had put off test driving the Ho...</td>\n",
       "      <td>[Automotive Enthusiasts: Bikes, Parts, and Tec...</td>\n",
       "      <td>Automotive Enthusiasts: Bikes, Parts, and Tech...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>14298</td>\n",
       "      <td>Motorcycling Community and Safety Discussions</td>\n",
       "      <td>[23, 43, 146, 147, 206, 218, 373, 414, 418, 42...</td>\n",
       "      <td>[I've only ever done it in an automatic. I was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>v6, taurus, jj, stanza, class cars</td>\n",
       "      <td>[v6, taurus, jj, stanza, class cars, rr aero-e...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>My wife and I looked at, and drove one last fa...</td>\n",
       "      <td>[Discussions on American and Japanese Cars Per...</td>\n",
       "      <td>Discussions on American and Japanese Cars Perf...</td>\n",
       "      <td>[!SKIP!]: Discussions on American and Japanese...</td>\n",
       "      <td>79</td>\n",
       "      <td>Discussions on American and Japanese Cars Perf...</td>\n",
       "      <td>[20, 51, 81, 197, 214, 346, 357, 377, 663, 690...</td>\n",
       "      <td>[: \\n: I am considering buying a 1993 Chevy or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>null modem, irq line, serial port, interrupt, ...</td>\n",
       "      <td>[null modem, irq line, serial port, interrupt,...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Supra Fax Modem v.32bis external stand alone f...</td>\n",
       "      <td>[Serial Port Configuration and Interrupt Handl...</td>\n",
       "      <td>Serial Port Configuration and Interrupt Handli...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>7356</td>\n",
       "      <td>Serial Communication and Modem Technologies</td>\n",
       "      <td>[46, 84, 94, 126, 179, 282, 335, 422, 433, 443...</td>\n",
       "      <td>[Has anyone had any experience with a replacem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>guns, nra, accidental deaths, homicides, self-...</td>\n",
       "      <td>[guns, nra, accidental deaths, homicides, self...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Oh Christ, here we go again. I'm actually goin...</td>\n",
       "      <td>[Gun Control Debates: Rights, Safety, and Acci...</td>\n",
       "      <td>Gun Control Debates: Rights, Safety, and Accid...</td>\n",
       "      <td>[!SKIP!]: Gun Control Debates: Rights, Safety,...</td>\n",
       "      <td>68</td>\n",
       "      <td>Gun Control Debates: Rights, Safety, and Accid...</td>\n",
       "      <td>[122, 135, 358, 402, 409, 531, 711, 740, 824, ...</td>\n",
       "      <td>[}Dillon has published a letter in the Blue Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>111</td>\n",
       "      <td>25 mhz operational, fpu, motherboard, cache ca...</td>\n",
       "      <td>[25 mhz operational, fpu, motherboard, cache c...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>For sale in the Baltimore - DC Area\\n\\nOne Mac...</td>\n",
       "      <td>[Used Computer Hardware and Peripheral Sales L...</td>\n",
       "      <td>Used Computer Hardware and Peripheral Sales Li...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>12270</td>\n",
       "      <td>Macintosh Hardware Upgrades and Sales</td>\n",
       "      <td>[10, 28, 36, 57, 68, 104, 117, 118, 142, 151, ...</td>\n",
       "      <td>[the blood of the lamb.\\n\\nThis will be a hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>video card, windows drivers, vlb, stealth 24, ...</td>\n",
       "      <td>[video card, windows drivers, vlb, stealth 24,...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>I have uploaded the most recent Windows driver...</td>\n",
       "      <td>[Discussion on Kenai/Denali Workstations and G...</td>\n",
       "      <td>Discussion on Kenai/Denali Workstations and Gr...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>6624</td>\n",
       "      <td>Video Card Drivers and Hardware Discussions</td>\n",
       "      <td>[1, 45, 92, 149, 155, 204, 243, 256, 259, 278,...</td>\n",
       "      <td>[My brother is in the market for a high-perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>window manager, x11r5 lib, widget, colormap, app</td>\n",
       "      <td>[window manager, x11r5 lib, widget, colormap, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>We have a program written with X11R5 and Motif...</td>\n",
       "      <td>[X11 Window Management and Motif Programming I...</td>\n",
       "      <td>X11 Window Management and Motif Programming Is...</td>\n",
       "      <td>[!SKIP!]: X11 Window Management and Motif Prog...</td>\n",
       "      <td>60</td>\n",
       "      <td>X11 Window Management and Motif Programming Is...</td>\n",
       "      <td>[21, 111, 139, 203, 230, 266, 281, 327, 342, 3...</td>\n",
       "      <td>[Sorry, that's a feature.  The ICCCM specifies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>84</td>\n",
       "      <td>gif files, window, server, dxf, msdos graphics</td>\n",
       "      <td>[gif files, window, server, dxf, msdos graphic...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Hello,\\n\\nAnyone know of any source code I can...</td>\n",
       "      <td>[Technical Discussions on Bitmap Formats and G...</td>\n",
       "      <td>Technical Discussions on Bitmap Formats and Gr...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>5243</td>\n",
       "      <td>Graphics Programming and File Format Discussions</td>\n",
       "      <td>[32, 82, 100, 124, 143, 159, 191, 195, 226, 30...</td>\n",
       "      <td>[Has anybody generated an X server for Windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>123</td>\n",
       "      <td>god, bible, sin, church, christians</td>\n",
       "      <td>[god, bible, sin, church, christians, salvatio...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Andrew,\\n\\n   How I wish this were true, and h...</td>\n",
       "      <td>[Christian Perspectives on Homosexuality and S...</td>\n",
       "      <td>Christian Perspectives on Homosexuality and Sc...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>17943</td>\n",
       "      <td>Theological Debates on Biblical Interpretation</td>\n",
       "      <td>[9, 85, 128, 136, 158, 161, 187, 192, 212, 227...</td>\n",
       "      <td>[If a Christian means someone who believes in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>80</td>\n",
       "      <td>snapped authur garrett johnson, jim's, hausman...</td>\n",
       "      <td>[snapped authur garrett johnson, jim's, hausma...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Hey! Glad to have some serious and constructiv...</td>\n",
       "      <td>[Online Discussions on Culture, Politics, and ...</td>\n",
       "      <td>Online Discussions on Culture, Politics, and P...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>6472</td>\n",
       "      <td>Online Satire and Religious Debate Discussions</td>\n",
       "      <td>[86, 91, 180, 209, 258, 299, 331, 333, 359, 37...</td>\n",
       "      <td>[Feel free to patronize me all you like; I nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>existence of god, faith, atheists, theism, proofs</td>\n",
       "      <td>[existence of god, faith, atheists, theism, pr...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>Since this is alt.atheism, I hope you don't mi...</td>\n",
       "      <td>[Atheism, Religion, and Their Influence on Mus...</td>\n",
       "      <td>Atheism, Religion, and Their Influence on Musi...</td>\n",
       "      <td>{'system': '\\nYou are an expert at classifying...</td>\n",
       "      <td>14798</td>\n",
       "      <td>Debates on God, Faith, and Atheism</td>\n",
       "      <td>[56, 166, 168, 183, 186, 201, 271, 329, 388, 4...</td>\n",
       "      <td>[Oh, Bobby. You're priceless. Did I ever tell ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer  cluster_id  num_documents  \\\n",
       "0       1           0            121   \n",
       "1       1           1             45   \n",
       "2       1           2            126   \n",
       "3       1           3             47   \n",
       "4       1           4             37   \n",
       "5       1           5            146   \n",
       "6       1           6             40   \n",
       "7       1           7             78   \n",
       "8       1           8             36   \n",
       "9       1           9             48   \n",
       "10      1          10             37   \n",
       "11      1          11             39   \n",
       "12      1          12             59   \n",
       "13      1          13             76   \n",
       "14      1          14            108   \n",
       "15      1          15             95   \n",
       "16      1          16             38   \n",
       "17      1          17             47   \n",
       "18      1          18             50   \n",
       "19      1          19            111   \n",
       "20      1          20             66   \n",
       "21      1          21             75   \n",
       "22      1          22             84   \n",
       "23      1          23            123   \n",
       "24      1          24             80   \n",
       "25      1          25             68   \n",
       "\n",
       "                                     top_5_keyphrases  \\\n",
       "0               hockey, game, team, playoffs, players   \n",
       "1   x-soviet armenian government, turkish, muslim ...   \n",
       "2   patients, chronic, sci med, msg, intellect and...   \n",
       "3        braves, baseball, catcher, hitter, pinch hit   \n",
       "4        stats, total baseball, alomar, career, swing   \n",
       "5   encryption scheme, clipper chip, public key, k...   \n",
       "6   pulse dialing, box and faceplate screw, ground...   \n",
       "7   state of israel, arabs, palestinians, jews, ce...   \n",
       "8            orbit, spacecraft, solar, jupiter, pluto   \n",
       "9   space station redesign, moon, space shuttle, s...   \n",
       "10  objective morality, hudson me hudson, science ...   \n",
       "11  non-toxic tear gas, fbi thought, propane, fume...   \n",
       "12  batf agents, david koresh, compound, did the f...   \n",
       "13   tape drive, scsi controller, ide drives, hd, dma   \n",
       "14      amp, voltage, stereo, receiver, baden sys6626   \n",
       "15                      bike, honda, ride, lane, cars   \n",
       "16                 v6, taurus, jj, stanza, class cars   \n",
       "17  null modem, irq line, serial port, interrupt, ...   \n",
       "18  guns, nra, accidental deaths, homicides, self-...   \n",
       "19  25 mhz operational, fpu, motherboard, cache ca...   \n",
       "20  video card, windows drivers, vlb, stealth 24, ...   \n",
       "21   window manager, x11r5 lib, widget, colormap, app   \n",
       "22     gif files, window, server, dxf, msdos graphics   \n",
       "23                god, bible, sin, church, christians   \n",
       "24  snapped authur garrett johnson, jim's, hausman...   \n",
       "25  existence of god, faith, atheists, theism, proofs   \n",
       "\n",
       "                                       all_keyphrases  num_keyphrases  \\\n",
       "0   [hockey, game, team, playoffs, players, leafs,...              16   \n",
       "1   [x-soviet armenian government, turkish, muslim...              16   \n",
       "2   [patients, chronic, sci med, msg, intellect an...              16   \n",
       "3   [braves, baseball, catcher, hitter, pinch hit,...              16   \n",
       "4   [stats, total baseball, alomar, career, swing,...              16   \n",
       "5   [encryption scheme, clipper chip, public key, ...              16   \n",
       "6   [pulse dialing, box and faceplate screw, groun...              16   \n",
       "7   [state of israel, arabs, palestinians, jews, c...              16   \n",
       "8   [orbit, spacecraft, solar, jupiter, pluto, pro...              16   \n",
       "9   [space station redesign, moon, space shuttle, ...              16   \n",
       "10  [objective morality, hudson me hudson, science...              16   \n",
       "11  [non-toxic tear gas, fbi thought, propane, fum...              16   \n",
       "12  [batf agents, david koresh, compound, did the ...              16   \n",
       "13  [tape drive, scsi controller, ide drives, hd, ...              16   \n",
       "14  [amp, voltage, stereo, receiver, baden sys6626...              16   \n",
       "15  [bike, honda, ride, lane, cars, biker dod 1069...              16   \n",
       "16  [v6, taurus, jj, stanza, class cars, rr aero-e...              16   \n",
       "17  [null modem, irq line, serial port, interrupt,...              16   \n",
       "18  [guns, nra, accidental deaths, homicides, self...              16   \n",
       "19  [25 mhz operational, fpu, motherboard, cache c...              16   \n",
       "20  [video card, windows drivers, vlb, stealth 24,...              16   \n",
       "21  [window manager, x11r5 lib, widget, colormap, ...              16   \n",
       "22  [gif files, window, server, dxf, msdos graphic...              16   \n",
       "23  [god, bible, sin, church, christians, salvatio...              16   \n",
       "24  [snapped authur garrett johnson, jim's, hausma...              16   \n",
       "25  [existence of god, faith, atheists, theism, pr...              16   \n",
       "\n",
       "    num_exemplars                                     first_exemplar  \\\n",
       "0               8  NHL RESULTS FOR GAMES PLAYED 4/15/93.\\n\\n-----...   \n",
       "1               8  Turkish Historical Revision <9305111942@zuma.U...   \n",
       "2               8  Hate to wreck your elaborate theory, but Steve...   \n",
       "3               8  HEY!!! All you Yankee fans who've been knockin...   \n",
       "4               8  You're right: Thomas, Gonzalez, Sheffield, and...   \n",
       "5               8  ^^^^^^^^^^^^^^^^^^^\\\\n                        ...   \n",
       "6               8  Hey Serdar,\\n           What nationality are y...   \n",
       "7               8  Elias Davidsson writes...\\n \\n \\nED> The follo...   \n",
       "8               8  Archive-name: space/new_probes\\nLast-modified:...   \n",
       "9               8  In the April edition of \"One Small Step for a ...   \n",
       "10              8  I think that you are changing the meaning of \"...   \n",
       "11              8  Flash over is a frequent occurrence with indoo...   \n",
       "12              8  A few comments on the ATF's botched handling o...   \n",
       "13              8  I have had a SCSI and IDE drive working togeth...   \n",
       "14              8  FOR SALE!!!!\\n\\n1) Sony Car Stereo Amplifier (...   \n",
       "15              8  Sixteen days I had put off test driving the Ho...   \n",
       "16              8  My wife and I looked at, and drove one last fa...   \n",
       "17              8  Supra Fax Modem v.32bis external stand alone f...   \n",
       "18              8  Oh Christ, here we go again. I'm actually goin...   \n",
       "19              8  For sale in the Baltimore - DC Area\\n\\nOne Mac...   \n",
       "20              8  I have uploaded the most recent Windows driver...   \n",
       "21              8  We have a program written with X11R5 and Motif...   \n",
       "22              8  Hello,\\n\\nAnyone know of any source code I can...   \n",
       "23              8  Andrew,\\n\\n   How I wish this were true, and h...   \n",
       "24              8  Hey! Glad to have some serious and constructiv...   \n",
       "25              8  Since this is alt.atheism, I hope you don't mi...   \n",
       "\n",
       "                                       subtopics_list  \\\n",
       "0   [Comprehensive Analysis of NHL Game Outcomes, ...   \n",
       "1   [Armenian-Turkish Conflict and Historical Revi...   \n",
       "2   [Health Effects of MSG and Glutamate in Food C...   \n",
       "3   [In-Depth Analysis of Phillies and Mariners Pl...   \n",
       "4   [Comprehensive Evaluation of MLB Player Metric...   \n",
       "5   [Mailing List Management and FAQ Discussions i...   \n",
       "6   [Telecommunications Equipment and Dialing Tech...   \n",
       "7   [Israeli-Palestinian Conflict and Historical Q...   \n",
       "8   [Planetary Exploration Missions and Spacecraft...   \n",
       "9   [NASA Space Station Redesign and Lunar Mission...   \n",
       "10  [Debate on Objective Morality and Its Empirica...   \n",
       "11  [Waco Siege: Tear Gas, Fire, and Government Ac...   \n",
       "12  [Waco Siege and Government Response to Branch ...   \n",
       "13  [SCSI and IDE Storage Technologies for Mac and...   \n",
       "14  [Audio Equipment Sales and Electronic Measurem...   \n",
       "15  [Automotive Enthusiasts: Bikes, Parts, and Tec...   \n",
       "16  [Discussions on American and Japanese Cars Per...   \n",
       "17  [Serial Port Configuration and Interrupt Handl...   \n",
       "18  [Gun Control Debates: Rights, Safety, and Acci...   \n",
       "19  [Used Computer Hardware and Peripheral Sales L...   \n",
       "20  [Discussion on Kenai/Denali Workstations and G...   \n",
       "21  [X11 Window Management and Motif Programming I...   \n",
       "22  [Technical Discussions on Bitmap Formats and G...   \n",
       "23  [Christian Perspectives on Homosexuality and S...   \n",
       "24  [Online Discussions on Culture, Politics, and ...   \n",
       "25  [Atheism, Religion, and Their Influence on Mus...   \n",
       "\n",
       "                                       subtopics_text  \\\n",
       "0   Comprehensive Analysis of NHL Game Outcomes, S...   \n",
       "1   Armenian-Turkish Conflict and Historical Revis...   \n",
       "2   Health Effects of MSG and Glutamate in Food Co...   \n",
       "3   In-Depth Analysis of Phillies and Mariners Pla...   \n",
       "4   Comprehensive Evaluation of MLB Player Metrics...   \n",
       "5   Mailing List Management and FAQ Discussions in...   \n",
       "6   Telecommunications Equipment and Dialing Techn...   \n",
       "7   Israeli-Palestinian Conflict and Historical Qu...   \n",
       "8   Planetary Exploration Missions and Spacecraft ...   \n",
       "9   NASA Space Station Redesign and Lunar Mission ...   \n",
       "10  Debate on Objective Morality and Its Empirical...   \n",
       "11  Waco Siege: Tear Gas, Fire, and Government Acc...   \n",
       "12  Waco Siege and Government Response to Branch D...   \n",
       "13  SCSI and IDE Storage Technologies for Mac and ...   \n",
       "14  Audio Equipment Sales and Electronic Measureme...   \n",
       "15  Automotive Enthusiasts: Bikes, Parts, and Tech...   \n",
       "16  Discussions on American and Japanese Cars Perf...   \n",
       "17  Serial Port Configuration and Interrupt Handli...   \n",
       "18  Gun Control Debates: Rights, Safety, and Accid...   \n",
       "19  Used Computer Hardware and Peripheral Sales Li...   \n",
       "20  Discussion on Kenai/Denali Workstations and Gr...   \n",
       "21  X11 Window Management and Motif Programming Is...   \n",
       "22  Technical Discussions on Bitmap Formats and Gr...   \n",
       "23  Christian Perspectives on Homosexuality and Sc...   \n",
       "24  Online Discussions on Culture, Politics, and P...   \n",
       "25  Atheism, Religion, and Their Influence on Musi...   \n",
       "\n",
       "                                       prompt_preview  prompt_length  \\\n",
       "0   {'system': '\\nYou are an expert at classifying...          19817   \n",
       "1   [!SKIP!]: Armenian-Turkish Conflict and Histor...             78   \n",
       "2   {'system': '\\nYou are an expert at classifying...           9422   \n",
       "3   [!SKIP!]: In-Depth Analysis of Phillies and Ma...             78   \n",
       "4   {'system': '\\nYou are an expert at classifying...           8872   \n",
       "5   {'system': '\\nYou are an expert at classifying...          22347   \n",
       "6   [!SKIP!]: Telecommunications Equipment and Dia...             73   \n",
       "7   {'system': '\\nYou are an expert at classifying...          22035   \n",
       "8   [!SKIP!]: Planetary Exploration Missions and S...             68   \n",
       "9   {'system': '\\nYou are an expert at classifying...          18020   \n",
       "10  [!SKIP!]: Debate on Objective Morality and Its...             68   \n",
       "11  {'system': '\\nYou are an expert at classifying...           9708   \n",
       "12  {'system': '\\nYou are an expert at classifying...          10702   \n",
       "13  {'system': '\\nYou are an expert at classifying...           7629   \n",
       "14  {'system': '\\nYou are an expert at classifying...           8282   \n",
       "15  {'system': '\\nYou are an expert at classifying...          14298   \n",
       "16  [!SKIP!]: Discussions on American and Japanese...             79   \n",
       "17  {'system': '\\nYou are an expert at classifying...           7356   \n",
       "18  [!SKIP!]: Gun Control Debates: Rights, Safety,...             68   \n",
       "19  {'system': '\\nYou are an expert at classifying...          12270   \n",
       "20  {'system': '\\nYou are an expert at classifying...           6624   \n",
       "21  [!SKIP!]: X11 Window Management and Motif Prog...             60   \n",
       "22  {'system': '\\nYou are an expert at classifying...           5243   \n",
       "23  {'system': '\\nYou are an expert at classifying...          17943   \n",
       "24  {'system': '\\nYou are an expert at classifying...           6472   \n",
       "25  {'system': '\\nYou are an expert at classifying...          14798   \n",
       "\n",
       "                                       llm_topic_name  \\\n",
       "0             NHL Game Strategies and Player Analysis   \n",
       "1   Armenian-Turkish Conflict and Historical Revis...   \n",
       "2           Chronic Health Issues and Dietary Effects   \n",
       "3   In-Depth Analysis of Phillies and Mariners Pla...   \n",
       "4     In-depth Analysis of Baseball Player Statistics   \n",
       "5   Encryption Controversies and Government Survei...   \n",
       "6   Telecommunications Equipment and Dialing Techn...   \n",
       "7   Israeli-Palestinian Conflict and Holocaust Dis...   \n",
       "8   Planetary Exploration Missions and Spacecraft ...   \n",
       "9         NASA Space Station and Astronomy Challenges   \n",
       "10  Debate on Objective Morality and Its Empirical...   \n",
       "11       Waco Siege: Chemical Exposure and Fire Risks   \n",
       "12       Waco Siege and Branch Davidian Controversies   \n",
       "13       Hard Disk and Storage Technology Discussions   \n",
       "14       Audio Equipment Sales and Signal Measurement   \n",
       "15      Motorcycling Community and Safety Discussions   \n",
       "16  Discussions on American and Japanese Cars Perf...   \n",
       "17        Serial Communication and Modem Technologies   \n",
       "18  Gun Control Debates: Rights, Safety, and Accid...   \n",
       "19              Macintosh Hardware Upgrades and Sales   \n",
       "20        Video Card Drivers and Hardware Discussions   \n",
       "21  X11 Window Management and Motif Programming Is...   \n",
       "22   Graphics Programming and File Format Discussions   \n",
       "23     Theological Debates on Biblical Interpretation   \n",
       "24     Online Satire and Religious Debate Discussions   \n",
       "25                 Debates on God, Faith, and Atheism   \n",
       "\n",
       "                                     document_indices  \\\n",
       "0   [0, 8, 24, 44, 66, 76, 96, 130, 174, 211, 228,...   \n",
       "1   [2, 15, 64, 93, 112, 113, 182, 188, 265, 304, ...   \n",
       "2   [34, 164, 190, 233, 253, 263, 269, 303, 337, 3...   \n",
       "3   [33, 144, 171, 318, 371, 378, 458, 470, 802, 9...   \n",
       "4   [60, 90, 116, 225, 379, 395, 497, 509, 557, 64...   \n",
       "5   [48, 53, 73, 133, 140, 141, 169, 215, 217, 224...   \n",
       "6   [6, 49, 78, 88, 98, 198, 285, 334, 524, 568, 6...   \n",
       "7   [102, 153, 274, 332, 339, 415, 510, 559, 567, ...   \n",
       "8   [14, 40, 210, 234, 296, 324, 479, 489, 698, 78...   \n",
       "9   [110, 154, 311, 322, 375, 437, 506, 514, 581, ...   \n",
       "10  [29, 216, 275, 305, 343, 389, 438, 459, 464, 6...   \n",
       "11  [17, 26, 97, 207, 247, 401, 423, 543, 582, 881...   \n",
       "12  [31, 52, 129, 280, 306, 315, 321, 336, 353, 38...   \n",
       "13  [3, 4, 16, 134, 148, 213, 248, 277, 307, 317, ...   \n",
       "14  [47, 50, 65, 115, 125, 157, 163, 178, 189, 236...   \n",
       "15  [23, 43, 146, 147, 206, 218, 373, 414, 418, 42...   \n",
       "16  [20, 51, 81, 197, 214, 346, 357, 377, 663, 690...   \n",
       "17  [46, 84, 94, 126, 179, 282, 335, 422, 433, 443...   \n",
       "18  [122, 135, 358, 402, 409, 531, 711, 740, 824, ...   \n",
       "19  [10, 28, 36, 57, 68, 104, 117, 118, 142, 151, ...   \n",
       "20  [1, 45, 92, 149, 155, 204, 243, 256, 259, 278,...   \n",
       "21  [21, 111, 139, 203, 230, 266, 281, 327, 342, 3...   \n",
       "22  [32, 82, 100, 124, 143, 159, 191, 195, 226, 30...   \n",
       "23  [9, 85, 128, 136, 158, 161, 187, 192, 212, 227...   \n",
       "24  [86, 91, 180, 209, 258, 299, 331, 333, 359, 37...   \n",
       "25  [56, 166, 168, 183, 186, 201, 271, 329, 388, 4...   \n",
       "\n",
       "                                       document_texts  \n",
       "0   [I am sure some bashers of Pens fans are prett...  \n",
       "1   [Finally you said what you dream about. Medite...  \n",
       "2   [According to a previous poster, one should se...  \n",
       "3   [Be patient. He has a sore shoulder from crash...  \n",
       "4   [I don't buy this at all.  I think things are ...  \n",
       "5   [You're blowing smoke.  Qualcomm wants to sell...  \n",
       "6   [AE is in Dallas...try 214/241-6060 or 214/241...  \n",
       "7   [In the same way in which antisemite means ant...  \n",
       "8   [There is no notion of heliocentric, or even g...  \n",
       "9   [\"Space Station Redesign Leader Says Cost Goal...  \n",
       "10  [[ . . .]\\n\\nI am a relativist who would like ...  \n",
       "11  [.........\\nI, some years ago, almost became a...  \n",
       "12  [The explanations of Federal law enforcement o...  \n",
       "13  [Think!\\n\\nIt's the SCSI card doing the DMA tr...  \n",
       "14  [Counterpoint  SA-12\\n\\n85watts per channel\\nv...  \n",
       "15  [I've only ever done it in an automatic. I was...  \n",
       "16  [: \\n: I am considering buying a 1993 Chevy or...  \n",
       "17  [Has anyone had any experience with a replacem...  \n",
       "18  [}Dillon has published a letter in the Blue Pr...  \n",
       "19  [the blood of the lamb.\\n\\nThis will be a hard...  \n",
       "20  [My brother is in the market for a high-perfor...  \n",
       "21  [Sorry, that's a feature.  The ICCCM specifies...  \n",
       "22  [Has anybody generated an X server for Windows...  \n",
       "23  [If a Christian means someone who believes in ...  \n",
       "24  [Feel free to patronize me all you like; I nee...  \n",
       "25  [Oh, Bobby. You're priceless. Did I ever tell ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_with_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audit_with_docs['document_texts'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Limited Documents per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit with limited documents per cluster:\n",
      "\n",
      "Cluster 0: NHL Broadcast Coverage and ESPN Scheduling Discussions\n",
      "  Total documents in cluster: 25\n",
      "  Showing first 3 documents:\n",
      "    [7] [stuff deleted]\n",
      "\n",
      "Ok, here's the solution to your problem.  Move to Canada.  Yesterday I was able\n",
      "to ...\n",
      "    [79] Well I think whenever ESPN covers the game they do a wonderful job. But\n",
      "   what I don't understand i...\n",
      "    [103] I haven't heard any news about ASN carrying any games but the local\n",
      "cable station here in St. John's...\n",
      "\n",
      "Cluster 1: Comprehensive Analysis of NHL Game Outcomes, Standings, and Player Metrics\n",
      "  Total documents in cluster: 18\n",
      "  Showing first 3 documents:\n",
      "    [44] Here are the NHL's alltime leaders in goals and points at the end of\n",
      "the 1992-3 season. Again, much ...\n",
      "    [76] Why not? I believe both the Devils and Islanders got 87 points.\n",
      "Say for example, another team had th...\n",
      "    [211] [Much text deleted]\n",
      "\n",
      ":   plus/minus ... it is the most misleading hockey stat available.\n",
      "\n",
      "Not necess...\n",
      "\n",
      "Cluster 2: In-Depth Discussions on NHL Game Strategies and Player Performance Insights\n",
      "  Total documents in cluster: 25\n",
      "  Showing first 3 documents:\n",
      "    [0] I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about th...\n",
      "    [174] Dear Ulf,\n",
      "\n",
      "\tWould you possibly consider helpiMontreal Canadiens fans everywhere\n",
      "by throwing a knee-c...\n",
      "    [574] J<--> \n",
      "J<--> Yahooooooooooooooooooooo!\n",
      "J<--> \n",
      "J<--> What a game, we finally beat those diques...and ...\n"
     ]
    }
   ],
   "source": [
    "# Create audit with limited documents (useful for large datasets)\n",
    "audit_limited = create_audit_df(\n",
    "    topic_model,\n",
    "    layer_index=0,\n",
    "    include_all_docs=True,\n",
    "    max_docs_per_cluster=3,  # Only show first 3 documents\n",
    "    original_texts=original_texts\n",
    ")\n",
    "\n",
    "print(\"Audit with limited documents per cluster:\")\n",
    "for idx, row in audit_limited.head(3).iterrows():\n",
    "    print(f\"\\nCluster {row['cluster_id']}: {row['llm_topic_name']}\")\n",
    "    print(f\"  Total documents in cluster: {row.get('total_docs_in_cluster', row['num_documents'])}\")\n",
    "    \n",
    "    if 'document_sample' in row:\n",
    "        print(f\"  Showing first {len(row['document_sample'])} documents:\")\n",
    "        for i, doc in enumerate(row['document_sample']):\n",
    "            print(f\"    [{row['document_indices'][i]}] {doc[:100]}...\")\n",
    "    elif 'document_texts' in row:\n",
    "        # If cluster has 3 or fewer docs, they'll be in document_texts\n",
    "        print(f\"  All {len(row['document_texts'])} documents:\")\n",
    "        for i, doc in enumerate(row['document_texts']):\n",
    "            print(f\"    [{row['document_indices'][i]}] {doc[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Using the get_cluster_documents Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: In-Depth Discussions on NHL Game Strategies and Player Performance Insights\n",
      "Total documents: 25\n",
      "\n",
      "Document indices: [0, 174, 574, 718, 850, 933, 972, 1149, 1254, 1263, 1577, 1606, 1620, 1689, 1749, 1813, 1842, 1974, 2083, 2206, 2607, 2613, 2768, 2826, 2989]\n",
      "\n",
      "First 3 documents:\n",
      "\n",
      "[Document 0]:\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I...\n",
      "\n",
      "[Document 174]:\n",
      "Dear Ulf,\n",
      "\n",
      "\tWould you possibly consider helpiMontreal Canadiens fans everywhere\n",
      "by throwing a knee-check in the direction of Denis Savard during your upcoming\n",
      "game against Montreal? We just can't seem...\n",
      "\n",
      "[Document 574]:\n",
      "J<--> \n",
      "J<--> Yahooooooooooooooooooooo!\n",
      "J<--> \n",
      "J<--> What a game, we finally beat those diques...and in O.T.!\n",
      "J<--> The Habs dominated this game and especially in O.T..\n",
      "\n",
      "You realize that we dominated g...\n"
     ]
    }
   ],
   "source": [
    "# Import the new helper function\n",
    "from toponymy.audit import get_cluster_documents\n",
    "\n",
    "# Get all documents for a specific cluster\n",
    "cluster_id = 2  # Choose a cluster to examine\n",
    "cluster_docs = get_cluster_documents(\n",
    "    topic_model, \n",
    "    layer_index=0, \n",
    "    cluster_id=cluster_id, \n",
    "    original_texts=original_texts\n",
    ")\n",
    "\n",
    "print(f\"Cluster {cluster_id}: {topic_model.cluster_layers_[0].topic_names[cluster_id]}\")\n",
    "print(f\"Total documents: {cluster_docs['total_count']}\")\n",
    "print(f\"\\nDocument indices: {cluster_docs['indices']}\")\n",
    "print(f\"\\nFirst 3 documents:\")\n",
    "for idx, text in zip(cluster_docs['indices'][:3], cluster_docs['texts'][:3]):\n",
    "    print(f\"\\n[Document {idx}]:\")\n",
    "    print(text[:200] + \"...\" if len(text) > 200 else text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Tracing Keyphrases Back to Original Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Cluster 0: NHL Broadcast Coverage and ESPN Scheduling Discussions\n",
      "\n",
      "Top 5 keyphrases: espn bought, zones abc, hockey games, coverage sunday april, cbc\n",
      "Checking these keyphrases in 25 cluster documents:\n",
      "\n",
      "'espn bought' appears in:\n",
      "  Doc [1435]: ...all of you\n",
      "who are unaware -> ESPN bought the air time from ABC and did...\n",
      "  Doc [2642]: ... the entire playoffs).  Since ESPN bought the\n",
      "SCA contract, there are l...\n",
      "\n",
      "'zones abc' appears in:\n",
      "  Not found as exact match in any document\n",
      "\n",
      "'hockey games' appears in:\n",
      "  Doc [751]: ...eninsula that will be showing ****hockey games****.  I'm looking for something \n",
      "...\n",
      "  Doc [1799]: ...n decided not\n",
      "to televise the ****hockey games****.  La directrous de programme ...\n"
     ]
    }
   ],
   "source": [
    "# Trace keyphrases back to their source documents\n",
    "layer = topic_model.cluster_layers_[0]\n",
    "\n",
    "# Pick a cluster to analyze\n",
    "cluster_id = 0\n",
    "print(f\"Analyzing Cluster {cluster_id}: {layer.topic_names[cluster_id]}\")\n",
    "\n",
    "# Get keyphrases and documents for this cluster\n",
    "keyphrases = layer.keyphrases[cluster_id][:5]  # Top 5 keyphrases\n",
    "cluster_docs = get_cluster_documents(topic_model, 0, cluster_id, original_texts)\n",
    "\n",
    "print(f\"\\nTop 5 keyphrases: {', '.join(keyphrases)}\")\n",
    "print(f\"Checking these keyphrases in {cluster_docs['total_count']} cluster documents:\")\n",
    "\n",
    "# For each keyphrase, find which documents contain it\n",
    "for kp in keyphrases[:3]:  # Check top 3 keyphrases\n",
    "    print(f\"\\n'{kp}' appears in:\")\n",
    "    occurrences = []\n",
    "    \n",
    "    for idx, doc in zip(cluster_docs['indices'], cluster_docs['texts']):\n",
    "        if kp.lower() in doc.lower():\n",
    "            # Find the position and show context\n",
    "            pos = doc.lower().find(kp.lower())\n",
    "            start = max(0, pos - 30)\n",
    "            end = min(len(doc), pos + len(kp) + 30)\n",
    "            context = doc[start:end]\n",
    "            \n",
    "            # Highlight the keyphrase\n",
    "            context = context.replace(kp, f\"**{kp}**\")\n",
    "            context = context.replace(kp.lower(), f\"**{kp.lower()}**\")\n",
    "            context = context.replace(kp.capitalize(), f\"**{kp.capitalize()}**\")\n",
    "            \n",
    "            occurrences.append((idx, context))\n",
    "    \n",
    "    if occurrences:\n",
    "        for idx, context in occurrences[:2]:  # Show first 2 occurrences\n",
    "            print(f\"  Doc [{idx}]: ...{context}...\")\n",
    "        if len(occurrences) > 2:\n",
    "            print(f\"  ... and {len(occurrences) - 2} more occurrences\")\n",
    "    else:\n",
    "        print(f\"  Not found as exact match in any document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Comparing Exemplars with All Cluster Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Comprehensive Analysis of NHL Game Outcomes, Standings, and Player Metrics\n",
      "Total documents: 18\n",
      "Number of exemplars: 8\n",
      "Exemplar indices: [994, 642, 76, 794, 609, 537, 211, 2343]\n",
      "\n",
      "Exemplar documents (most representative):\n",
      "\n",
      "[Exemplar 1 - Document 994]:\n",
      "NHL RESULTS FOR GAMES PLAYED 4/15/93.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                              ...\n",
      "\n",
      "[Exemplar 2 - Document 642]:\n",
      "Well tell us about your pool table!\n",
      "\n",
      "-=- Andy -=-...\n",
      "\n",
      "[Exemplar 3 - Document 76]:\n",
      "Why not? I believe both the Devils and Islanders got 87 points.\n",
      "Say for example, another team had this record : 20-37-47;\n",
      "they had 20*2+47*1+37*0=87 w...\n",
      "\n",
      "\n",
      "Non-exemplar documents (10 total):\n",
      "\n",
      "[Document 44]:\n",
      "Here are the NHL's alltime leaders in goals and points at the end of\n",
      "the 1992-3 season. Again, much thanks to Joseph Achkar.\n",
      "\n",
      "Carl\n",
      "\n",
      "Notes: An active p...\n",
      "\n",
      "[Document 370]:\n",
      "NHL RESULTS FOR GAMES PLAYED 4/05/93.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                              ...\n"
     ]
    }
   ],
   "source": [
    "# Compare exemplar documents with all documents in a cluster\n",
    "cluster_id = 1\n",
    "layer = topic_model.cluster_layers_[0]\n",
    "\n",
    "# Get cluster details including exemplar indices\n",
    "cluster_details = get_cluster_details(topic_model, 0, cluster_id)\n",
    "exemplar_indices = cluster_details.get('exemplar_indices', [])\n",
    "\n",
    "# Get all documents in the cluster\n",
    "all_docs = get_cluster_documents(topic_model, 0, cluster_id, original_texts)\n",
    "\n",
    "print(f\"Cluster {cluster_id}: {layer.topic_names[cluster_id]}\")\n",
    "print(f\"Total documents: {all_docs['total_count']}\")\n",
    "print(f\"Number of exemplars: {len(exemplar_indices)}\")\n",
    "print(f\"Exemplar indices: {exemplar_indices}\")\n",
    "\n",
    "# Show which documents are exemplars\n",
    "print(\"\\nExemplar documents (most representative):\")\n",
    "for i, ex_idx in enumerate(exemplar_indices[:3]):\n",
    "    if ex_idx in all_docs['indices']:\n",
    "        doc_position = all_docs['indices'].index(ex_idx)\n",
    "        print(f\"\\n[Exemplar {i+1} - Document {ex_idx}]:\")\n",
    "        print(all_docs['texts'][doc_position][:150] + \"...\")\n",
    "\n",
    "# Show non-exemplar documents\n",
    "non_exemplar_indices = [idx for idx in all_docs['indices'] if idx not in exemplar_indices]\n",
    "print(f\"\\n\\nNon-exemplar documents ({len(non_exemplar_indices)} total):\")\n",
    "for idx in non_exemplar_indices[:2]:\n",
    "    doc_position = all_docs['indices'].index(idx)\n",
    "    print(f\"\\n[Document {idx}]:\")\n",
    "    print(all_docs['texts'][doc_position][:150] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Analyzing Document Distribution Across Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document distribution analysis:\n",
      "Total documents: 3000\n",
      "Clustered documents: 1754\n",
      "Unclustered documents: 1246\n",
      "\n",
      "Unclustered document indices: [3, 5, 9, 11, 12, 13, 17, 18, 19, 22]\n",
      "\n",
      "Sample unclustered documents:\n",
      "\n",
      "[Document 3]:\n",
      "Think!\n",
      "\n",
      "It's the SCSI card doing the DMA transfers NOT the disks...\n",
      "\n",
      "The SCSI card can do DMA transfers containing data from any of the SCSI devices\n",
      "i...\n",
      "\n",
      "[Document 5]:\n",
      "Back in high school I worked as a lab assistant for a bunch of experimental\n",
      "psychologists at Bell Labs.  When they were doing visual perception and\n",
      "me...\n",
      "\n",
      "[Document 9]:\n",
      "If a Christian means someone who believes in the divinity of Jesus, it is safe\n",
      "to say that Jesus was a Christian.\n",
      "--\n",
      "\"On the first day after Christmas...\n",
      "\n",
      "\n",
      "Document coverage by cluster:\n",
      "Cluster 0: 25 docs (0.8%) - NHL Broadcast Coverage and ESPN Scheduling Discuss...\n",
      "Cluster 1: 18 docs (0.6%) - Comprehensive Analysis of NHL Game Outcomes, Stand...\n",
      "Cluster 2: 25 docs (0.8%) - In-Depth Discussions on NHL Game Strategies and Pl...\n",
      "Cluster 3: 10 docs (0.3%) - Discussion on Software Copy Protection and Circumv...\n",
      "Cluster 4: 10 docs (0.3%) - Discussions on Goalie Equipment and Masks in Hocke...\n",
      "Cluster 5: 10 docs (0.3%) - NHL European Player Representation and Management ...\n",
      "Cluster 6: 12 docs (0.4%) - NCAA Hockey Discussions and Coaching Changes in Pr...\n",
      "Cluster 7: 15 docs (0.5%) - NHL Trades, Strategies, and Player Prospects Discu...\n",
      "Cluster 8: 10 docs (0.3%) - Youth Drug Use, Health Insurance, and Poverty in W...\n",
      "Cluster 9: 13 docs (0.4%) - Engineering Challenges in Fossil Fuel Plants and R...\n",
      "Cluster 10: 45 docs (1.5%) - Armenian-Turkish Conflict and Historical Revisioni...\n",
      "Cluster 11: 47 docs (1.6%) - In-Depth Analysis of Phillies and Mariners Player ...\n",
      "Cluster 12: 40 docs (1.3%) - Telecommunications Equipment and Dialing Technique...\n",
      "Cluster 13: 18 docs (0.6%) - Printer Drivers and Upgrades for Deskjet and Laser...\n",
      "Cluster 14: 10 docs (0.3%) - TrueType Font Issues and Solutions for Windows Sys...\n",
      "Cluster 15: 12 docs (0.4%) - Mailing List Management and FAQ Discussions in Aca...\n",
      "Cluster 16: 13 docs (0.4%) - Comprehensive Evaluation of MLB Player Metrics and...\n",
      "Cluster 17: 18 docs (0.6%) - Critical Discussions on Baseball Statistics and Pl...\n",
      "Cluster 18: 13 docs (0.4%) - Discussion on Newsgroup Structure and Readership i...\n",
      "Cluster 19: 10 docs (0.3%) - Bosnian War, Muslim Identity, and International Re...\n",
      "Cluster 20: 10 docs (0.3%) - Cryptography Research and Legal Issues Surrounding...\n",
      "Cluster 21: 20 docs (0.7%) - Chemical Solutions and Practical Applications for ...\n",
      "Cluster 22: 16 docs (0.5%) - Health Effects of MSG and Glutamate in Food Consum...\n",
      "Cluster 23: 54 docs (1.8%) - Medical Discussions on Candida, Migraines, and Pat...\n",
      "Cluster 24: 36 docs (1.2%) - Planetary Exploration Missions and Spacecraft Traj...\n",
      "Cluster 25: 32 docs (1.1%) - NASA Space Station Redesign and Lunar Mission Budg...\n",
      "Cluster 26: 15 docs (0.5%) - Impact of Light Pollution on Astronomy and Space A...\n",
      "Cluster 27: 37 docs (1.2%) - Debate on Objective Morality and Its Empirical Fou...\n",
      "Cluster 28: 11 docs (0.4%) - Automotive Maintenance Issues and Solutions for Ma...\n",
      "Cluster 29: 12 docs (0.4%) - Encryption, Law Enforcement, and Key Escrow Contro...\n",
      "Cluster 30: 21 docs (0.7%) - Clipper Chip Controversy: Encryption, Privacy, and...\n",
      "Cluster 31: 12 docs (0.4%) - Debate on Government Encryption Policies and Priva...\n",
      "Cluster 32: 29 docs (1.0%) - Waco Siege and Government Response to Branch David...\n",
      "Cluster 33: 12 docs (0.4%) - Religious Cults, Political Independence, and Cultu...\n",
      "Cluster 34: 14 docs (0.5%) - Waco Siege: Tear Gas, Fire, and Government Account...\n",
      "Cluster 35: 10 docs (0.3%) - Hazards of Inhalation and Flammability in Aerosoli...\n",
      "Cluster 36: 37 docs (1.2%) - Israeli-Palestinian Conflict and Historical Quotat...\n",
      "Cluster 37: 14 docs (0.5%) - Holocaust Denial and Anti-Semitism in Contemporary...\n",
      "Cluster 38: 38 docs (1.3%) - Discussions on American and Japanese Cars Performa...\n",
      "Cluster 39: 24 docs (0.8%) - SCSI and IDE Storage Technologies for Mac and PC S...\n",
      "Cluster 40: 26 docs (0.9%) - Hard Disk Configuration and Troubleshooting in Com...\n",
      "Cluster 41: 18 docs (0.6%) - Automotive Enthusiasts: Bikes, Parts, and Technica...\n",
      "Cluster 42: 14 docs (0.5%) - Motorcycle Enthusiasts Discussing Models and Perfo...\n",
      "Cluster 43: 50 docs (1.7%) - Audio Equipment Sales and Electronic Measurement D...\n",
      "Cluster 44: 24 docs (0.8%) - Radio Frequency Measurement and Signal Interferenc...\n",
      "Cluster 45: 50 docs (1.7%) - Gun Control Debates: Rights, Safety, and Accidenta...\n",
      "Cluster 46: 14 docs (0.5%) - Debate on Death Penalty Ethics and Moral Implicati...\n",
      "Cluster 47: 19 docs (0.6%) - Comic Books, CDs, and Movie Merchandise for Sale...\n",
      "Cluster 48: 17 docs (0.6%) - Drunk Driving Issues Among Motorcyclists and Traff...\n",
      "Cluster 49: 22 docs (0.7%) - Motorcycling Experiences and Community Discussions...\n",
      "Cluster 50: 17 docs (0.6%) - Serial Port Configuration and Interrupt Handling i...\n",
      "Cluster 51: 20 docs (0.7%) - Modems, Fax, and Voice Communication Technologies ...\n",
      "Cluster 52: 23 docs (0.8%) - Libertarian Perspectives on Government, Economics,...\n",
      "Cluster 53: 21 docs (0.7%) - DOS and Windows Memory Management and Resource Iss...\n",
      "Cluster 54: 15 docs (0.5%) - Statistical Analysis of Sexual Behavior Among Gay ...\n",
      "Cluster 55: 24 docs (0.8%) - Technical Issues with Apple Duo and Video Hardware...\n",
      "Cluster 56: 31 docs (1.0%) - Discussions on Windows NT, OS/2, and Application C...\n",
      "Cluster 57: 10 docs (0.3%) - Debates on Islamic Teachings, Khomeini, and Religi...\n",
      "Cluster 58: 16 docs (0.5%) - Debate on Abortion Rights and Sexual Orientation I...\n",
      "Cluster 59: 10 docs (0.3%) - Public Domain Motif Toolkit and Widget Support Dis...\n",
      "Cluster 60: 28 docs (0.9%) - Used Computer Hardware and Peripheral Sales Listin...\n",
      "Cluster 61: 14 docs (0.5%) - Macintosh Memory Upgrades and Compatibility Issues...\n",
      "Cluster 62: 41 docs (1.4%) - Upgrading and Compatibility of 386/486 PC Componen...\n",
      "Cluster 63: 16 docs (0.5%) - Computer Hardware and CAD Software Discussions for...\n",
      "Cluster 64: 75 docs (2.5%) - X11 Window Management and Motif Programming Issues...\n",
      "Cluster 65: 19 docs (0.6%) - Discussion on Kenai/Denali Workstations and Graphi...\n",
      "Cluster 66: 35 docs (1.2%) - VLB Video Cards and Driver Discussions for Windows...\n",
      "Cluster 67: 17 docs (0.6%) - Technical Discussions on Bitmap Formats and Graphi...\n",
      "Cluster 68: 23 docs (0.8%) - Image File Format Conversion and Graphics Software...\n",
      "Cluster 69: 26 docs (0.9%) - Atheism, Religion, and Their Influence on Music an...\n",
      "Cluster 70: 37 docs (1.2%) - Debates on Existence of God and Christian Faith Ch...\n",
      "Cluster 71: 13 docs (0.4%) - Christian Perspectives on Homosexuality and Script...\n",
      "Cluster 72: 18 docs (0.6%) - Online Discussions on Culture, Politics, and Perso...\n",
      "Cluster 73: 12 docs (0.4%) - X Window System Applications and Shared Memory Man...\n",
      "Cluster 74: 16 docs (0.5%) - Cross-Platform User Interface Development and X Wi...\n",
      "Cluster 75: 33 docs (1.1%) - Satirical Discussions and Flame Wars in Online New...\n",
      "Cluster 76: 15 docs (0.5%) - Debates on Religious Neutrality and Public School ...\n",
      "Cluster 77: 25 docs (0.8%) - Theological Discussions on Sin, Salvation, and Div...\n",
      "Cluster 78: 12 docs (0.4%) - Critical Examination of Biblical Texts and Histori...\n",
      "Cluster 79: 10 docs (0.3%) - Debates on Orthodox Christian Beliefs and Biblical...\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame showing document coverage across clusters\n",
    "audit_df = create_audit_df(topic_model, layer_index=0)\n",
    "\n",
    "# Build a document-to-cluster mapping\n",
    "doc_cluster_map = {}\n",
    "for _, row in audit_df.iterrows():\n",
    "    cluster_id = row['cluster_id']\n",
    "    topic_name = row['llm_topic_name']\n",
    "    for doc_idx in row['document_indices']:\n",
    "        doc_cluster_map[doc_idx] = {\n",
    "            'cluster_id': cluster_id,\n",
    "            'topic_name': topic_name\n",
    "        }\n",
    "\n",
    "# Find any unclustered documents\n",
    "all_doc_indices = set(range(len(original_texts)))\n",
    "clustered_indices = set(doc_cluster_map.keys())\n",
    "unclustered_indices = all_doc_indices - clustered_indices\n",
    "\n",
    "print(f\"Document distribution analysis:\")\n",
    "print(f\"Total documents: {len(original_texts)}\")\n",
    "print(f\"Clustered documents: {len(clustered_indices)}\")\n",
    "print(f\"Unclustered documents: {len(unclustered_indices)}\")\n",
    "\n",
    "if unclustered_indices:\n",
    "    print(f\"\\nUnclustered document indices: {sorted(list(unclustered_indices))[:10]}\")\n",
    "    print(\"\\nSample unclustered documents:\")\n",
    "    for idx in sorted(list(unclustered_indices))[:3]:\n",
    "        print(f\"\\n[Document {idx}]:\")\n",
    "        print(original_texts[idx][:150] + \"...\")\n",
    "\n",
    "# Show document coverage by cluster\n",
    "print(\"\\n\\nDocument coverage by cluster:\")\n",
    "for _, row in audit_df.iterrows():\n",
    "    percentage = (row['num_documents'] / len(original_texts)) * 100\n",
    "    print(f\"Cluster {row['cluster_id']}: {row['num_documents']} docs ({percentage:.1f}%) - {row['llm_topic_name'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of New Document Traceability Features\n",
    "\n",
    "The enhanced audit functionality now provides several ways to trace back to original documents:\n",
    "\n",
    "1. **`document_indices`** - Always included in audit DataFrames, showing which documents belong to each cluster\n",
    "\n",
    "2. **`include_all_docs=True`** - Adds full document texts to the audit DataFrame:\n",
    "   - `document_texts` column contains all document texts for each cluster\n",
    "   - Requires passing `original_texts` parameter\n",
    "\n",
    "3. **`max_docs_per_cluster`** - Limits the number of documents shown per cluster:\n",
    "   - Creates `document_sample` column with limited documents\n",
    "   - Adds `total_docs_in_cluster` to show the actual count\n",
    "\n",
    "4. **`get_cluster_documents()`** - Helper function to easily retrieve all documents for a specific cluster:\n",
    "   - Returns indices, texts, and total count\n",
    "   - Supports `max_docs` parameter for limiting results\n",
    "\n",
    "These features enable:\n",
    "- Validating that clusters contain semantically related documents\n",
    "- Tracing how keyphrases were extracted from actual document content\n",
    "- Understanding why certain documents were grouped together\n",
    "- Debugging clustering quality issues\n",
    "- Creating detailed audit reports with full traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (toponymy-test)",
   "language": "python",
   "name": "toponymy-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
